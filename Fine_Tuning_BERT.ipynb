{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Fine-Tuning BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4cdacd5286384965a4241c45003b0260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5b9e0e57f864455a4709bae62fc1d8e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61a6dc466e52477ea0da28e71ab5eb19",
              "IPY_MODEL_04563fd5dce9421ab3a0391d950f48d4"
            ]
          }
        },
        "c5b9e0e57f864455a4709bae62fc1d8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61a6dc466e52477ea0da28e71ab5eb19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_488fac3346ae4653ba9d22e8570eda81",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7086d1e7f9e24713978a9e4de77b9998"
          }
        },
        "04563fd5dce9421ab3a0391d950f48d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_738626a884bd45658d0b553751a622e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:30&lt;00:00, 14.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_234f9a29556541a398bd3cdbdfc91363"
          }
        },
        "488fac3346ae4653ba9d22e8570eda81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7086d1e7f9e24713978a9e4de77b9998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "738626a884bd45658d0b553751a622e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "234f9a29556541a398bd3cdbdfc91363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8963551c8f894ca8a1aace9b5184f82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_453e5421d9924687a7484b06c4825ea3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a4e441d94cb44d24918198c2e156865d",
              "IPY_MODEL_e98997f8b528459c86acdd01dcca3080"
            ]
          }
        },
        "453e5421d9924687a7484b06c4825ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4e441d94cb44d24918198c2e156865d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8d1cd667f48f4a4e8f5c9372991ef843",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff32f251207845fab3dd6481e7564fa7"
          }
        },
        "e98997f8b528459c86acdd01dcca3080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4136eac3dba24c1a81945fe0ef677e91",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:29&lt;00:00, 14.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a1a015354144498b75ddb35312eff80"
          }
        },
        "8d1cd667f48f4a4e8f5c9372991ef843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff32f251207845fab3dd6481e7564fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4136eac3dba24c1a81945fe0ef677e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a1a015354144498b75ddb35312eff80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e539952280fa490cb29a16a386b1eea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c0e190b0e5a1465c982b404eb6e13c6b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a9a6244799f446c4bc4d78c033742653",
              "IPY_MODEL_5ed0acd64356410d9b40ebcf07cf024b"
            ]
          }
        },
        "c0e190b0e5a1465c982b404eb6e13c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9a6244799f446c4bc4d78c033742653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cbd646674ada4ef692bb656eb4aa8598",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad8a8fcb244a4691860bfe0cb5aeaf8c"
          }
        },
        "5ed0acd64356410d9b40ebcf07cf024b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ddc272fd62e41cb827c87c6f7bd8a1c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:05&lt;00:00, 46.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9811cd06dbe64cc1a8c94c56f05e89a4"
          }
        },
        "cbd646674ada4ef692bb656eb4aa8598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad8a8fcb244a4691860bfe0cb5aeaf8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ddc272fd62e41cb827c87c6f7bd8a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9811cd06dbe64cc1a8c94c56f05e89a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashinshanly/BERT-FineTuned-RD/blob/main/Fine_Tuning_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFOTiqrtNvyy"
      },
      "source": [
        "# Install Transformers Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hkhc10wNrGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840159db-f768-4d09-b63e-f8438e67d2bc"
      },
      "source": [
        "# 1\n",
        "!pip install transformers==3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 8.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 17.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 56.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2020.11.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=44a406775863ff0d02bf9a32fd518eef32b22e281294dd121cdb66edacb27b0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4giRzM7NtHJ"
      },
      "source": [
        "# 2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl-99OyJDV0S",
        "outputId": "0070b682-8daf-4413-89ea-99efc27ea96e"
      },
      "source": [
        "# 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKd-Tj3hOMsZ"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "cwJrQFQgN_BE",
        "outputId": "56a11726-0bd8-4f57-de53-838407d60ba6"
      },
      "source": [
        "# 4\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/ReverseDictionary/data/dataset2.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abandon</td>\n",
              "      <td>Cease to support or look after (someone)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abandon</td>\n",
              "      <td>desert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ability</td>\n",
              "      <td>Possession of the means or skill to do something</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>able</td>\n",
              "      <td>Having the power skill means or opportunity to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abortion</td>\n",
              "      <td>The deliberate termination of a human pregnanc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text\n",
              "0   abandon           Cease to support or look after (someone)\n",
              "1   abandon                                             desert\n",
              "2   ability   Possession of the means or skill to do something\n",
              "3      able  Having the power skill means or opportunity to...\n",
              "4  abortion  The deliberate termination of a human pregnanc..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzPPOrVQWiW5",
        "outputId": "c36ddc6b-b886-4d76-8258-3ef68c6a3471"
      },
      "source": [
        "# 5\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3281, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "676DPU1BOPdp",
        "outputId": "c03da707-7c5e-497e-c636-beaa889d0e07"
      },
      "source": [
        "# 6\n",
        "# check class distribution\n",
        "df['label'].value_counts(normalize = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "first       0.000914\n",
              "quite       0.000914\n",
              "one         0.000914\n",
              "universe    0.000914\n",
              "thirty      0.000914\n",
              "              ...   \n",
              "dear        0.000305\n",
              "pepper      0.000305\n",
              "desk        0.000305\n",
              "forget      0.000305\n",
              "quiet       0.000305\n",
              "Name: label, Length: 2842, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_dQ4MxZLgYS",
        "outputId": "7ef13963-4136-4ea4-ab1a-a54bb7879a72"
      },
      "source": [
        "# 7\n",
        "series=df['label']\n",
        "series.tolist()\n",
        "\n",
        "word2idx={}\n",
        "idx2word=[]\n",
        "for word in series:\n",
        "  if word not in word2idx:\n",
        "    word2idx[word]=len(word2idx)\n",
        "    idx2word.append(word)\n",
        "print(word2idx)\n",
        "print(len(word2idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'abandon': 0, 'ability': 1, 'able': 2, 'abortion': 3, 'about': 4, 'above': 5, 'abroad': 6, 'absence': 7, 'absolute': 8, 'absolutely': 9, 'absorb': 10, 'abuse': 11, 'academic': 12, 'accept': 13, 'access': 14, 'accident': 15, 'accompany': 16, 'accomplish': 17, 'according': 18, 'account': 19, 'accurate': 20, 'accuse': 21, 'achieve': 22, 'achievement': 23, 'acid': 24, 'acknowledge': 25, 'acquire': 26, 'across': 27, 'act': 28, 'action': 29, 'active': 30, 'activist': 31, 'activity': 32, 'actor': 33, 'actress': 34, 'actual': 35, 'actually': 36, 'ad': 37, 'adapt': 38, 'add': 39, 'addition': 40, 'additional': 41, 'address': 42, 'adequate': 43, 'adjust': 44, 'adjustment': 45, 'administration': 46, 'administrator': 47, 'admire': 48, 'admission': 49, 'admit': 50, 'adolescent': 51, 'adopt': 52, 'adult': 53, 'advance': 54, 'advanced': 55, 'advantage': 56, 'adventure': 57, 'advertising': 58, 'advice': 59, 'advise': 60, 'adviser': 61, 'advocate': 62, 'affair': 63, 'affect': 64, 'afford': 65, 'afraid': 66, 'after': 67, 'afternoon': 68, 'again': 69, 'against': 70, 'age': 71, 'agency': 72, 'agenda': 73, 'agent': 74, 'aggressive': 75, 'ago': 76, 'agree': 77, 'agreement': 78, 'agricultural': 79, 'ah': 80, 'ahead': 81, 'aid': 82, 'aide': 83, 'aim': 84, 'air': 85, 'aircraft': 86, 'airline': 87, 'airport': 88, 'album': 89, 'alcohol': 90, 'alive': 91, 'all': 92, 'alliance': 93, 'allow': 94, 'ally': 95, 'almost': 96, 'alone': 97, 'along': 98, 'already': 99, 'also': 100, 'alter': 101, 'alternative': 102, 'although': 103, 'always': 104, 'amazing': 105, 'among': 106, 'amount': 107, 'analysis': 108, 'analyst': 109, 'analyze': 110, 'ancient': 111, 'and': 112, 'anger': 113, 'angle': 114, 'angry': 115, 'animal': 116, 'anniversary': 117, 'announce': 118, 'annual': 119, 'another': 120, 'answer': 121, 'anticipate': 122, 'anxiety': 123, 'any': 124, 'anybody': 125, 'anymore': 126, 'anyone': 127, 'anything': 128, 'anyway': 129, 'anywhere': 130, 'apart': 131, 'apartment': 132, 'apparent': 133, 'apparently': 134, 'appeal': 135, 'appear': 136, 'appearance': 137, 'apple': 138, 'application': 139, 'apply': 140, 'appoint': 141, 'appointment': 142, 'appreciate': 143, 'approach': 144, 'appropriate': 145, 'approval': 146, 'approve': 147, 'approximately': 148, 'architect': 149, 'area': 150, 'argue': 151, 'argument': 152, 'arise': 153, 'arm': 154, 'armed': 155, 'army': 156, 'around': 157, 'arrange': 158, 'arrangement': 159, 'arrest': 160, 'arrival': 161, 'arrive': 162, 'art': 163, 'article': 164, 'artist': 165, 'artistic': 166, 'as': 167, 'aside': 168, 'ask': 169, 'asleep': 170, 'aspect': 171, 'assault': 172, 'assert': 173, 'assess': 174, 'assessment': 175, 'asset': 176, 'assign': 177, 'assignment': 178, 'assist': 179, 'assistance': 180, 'assistant': 181, 'associate': 182, 'association': 183, 'assume': 184, 'assumption': 185, 'assure': 186, 'at': 187, 'athlete': 188, 'athletic': 189, 'atmosphere': 190, 'attach': 191, 'attack': 192, 'attempt': 193, 'attend': 194, 'attention': 195, 'attitude': 196, 'attorney': 197, 'attract': 198, 'attractive': 199, 'attribute': 200, 'audience': 201, 'author': 202, 'authority': 203, 'auto': 204, 'available': 205, 'average': 206, 'avoid': 207, 'award': 208, 'aware': 209, 'awareness': 210, 'away': 211, 'awful': 212, 'baby': 213, 'back': 214, 'background': 215, 'bad': 216, 'badly': 217, 'bag': 218, 'bake': 219, 'balance': 220, 'ball': 221, 'ban': 222, 'band': 223, 'bank': 224, 'bar': 225, 'barely': 226, 'barrel': 227, 'barrier': 228, 'base': 229, 'baseball': 230, 'basic': 231, 'basically': 232, 'basis': 233, 'basket': 234, 'basketball': 235, 'bathroom': 236, 'battery': 237, 'battle': 238, 'be': 239, 'beach': 240, 'bean': 241, 'bear': 242, 'beat': 243, 'beautiful': 244, 'beauty': 245, 'because': 246, 'become': 247, 'bed': 248, 'bedroom': 249, 'beer': 250, 'before': 251, 'begin': 252, 'beginning': 253, 'behavior': 254, 'behind': 255, 'being': 256, 'belief': 257, 'believe': 258, 'bell': 259, 'belong': 260, 'below': 261, 'belt': 262, 'bench': 263, 'bend': 264, 'beneath': 265, 'benefit': 266, 'beside': 267, 'besides': 268, 'best': 269, 'bet': 270, 'better': 271, 'between': 272, 'beyond': 273, 'big': 274, 'bike': 275, 'bill': 276, 'billion': 277, 'bind': 278, 'biological': 279, 'bird': 280, 'birth': 281, 'birthday': 282, 'bit': 283, 'bite': 284, 'black': 285, 'blade': 286, 'blame': 287, 'blanket': 288, 'blind': 289, 'block': 290, 'blood': 291, 'blow': 292, 'blue': 293, 'board': 294, 'boat': 295, 'body': 296, 'bomb': 297, 'bombing': 298, 'bond': 299, 'bone': 300, 'book': 301, 'boom': 302, 'boot': 303, 'border': 304, 'born': 305, 'borrow': 306, 'boss': 307, 'both': 308, 'bother': 309, 'bottle': 310, 'bottom': 311, 'boundary': 312, 'bowl': 313, 'box': 314, 'boy': 315, 'boyfriend': 316, 'brain': 317, 'branch': 318, 'brand': 319, 'bread': 320, 'break': 321, 'breakfast': 322, 'breast': 323, 'breath': 324, 'breathe': 325, 'brick': 326, 'bridge': 327, 'brief': 328, 'briefly': 329, 'bright': 330, 'brilliant': 331, 'bring': 332, 'broad': 333, 'broken': 334, 'brother': 335, 'brown': 336, 'brush': 337, 'buck': 338, 'budget': 339, 'build': 340, 'building': 341, 'bullet': 342, 'bunch': 343, 'burden': 344, 'burn': 345, 'bury': 346, 'bus': 347, 'business': 348, 'busy': 349, 'but': 350, 'butter': 351, 'button': 352, 'buy': 353, 'buyer': 354, 'by': 355, 'cabin': 356, 'cabinet': 357, 'cable': 358, 'cake': 359, 'calculate': 360, 'call': 361, 'camera': 362, 'camp': 363, 'campaign': 364, 'campus': 365, 'can': 366, 'cancer': 367, 'candidate': 368, 'cap': 369, 'capability': 370, 'capable': 371, 'capacity': 372, 'capital': 373, 'captain': 374, 'capture': 375, 'car': 376, 'carbon': 377, 'card': 378, 'care': 379, 'career': 380, 'careful': 381, 'carefully': 382, 'carrier': 383, 'carry': 384, 'case': 385, 'cash': 386, 'cast': 387, 'cat': 388, 'catch': 389, 'category': 390, 'cause': 391, 'ceiling': 392, 'celebrate': 393, 'celebration': 394, 'celebrity': 395, 'cell': 396, 'center': 397, 'central': 398, 'century': 399, 'ceremony': 400, 'certain': 401, 'certainly': 402, 'chain': 403, 'chair': 404, 'chairman': 405, 'challenge': 406, 'chamber': 407, 'champion': 408, 'championship': 409, 'chance': 410, 'change': 411, 'changing': 412, 'channel': 413, 'chapter': 414, 'character': 415, 'characteristic': 416, 'characterize': 417, 'charge': 418, 'charity': 419, 'chart': 420, 'chase': 421, 'cheap': 422, 'check': 423, 'cheek': 424, 'cheese': 425, 'chef': 426, 'chemical': 427, 'chest': 428, 'chicken': 429, 'chief': 430, 'child': 431, 'childhood': 432, 'chip': 433, 'chocolate': 434, 'choice': 435, 'cholesterol': 436, 'choose': 437, 'church': 438, 'cigarette': 439, 'circle': 440, 'circumstance': 441, 'cite': 442, 'citizen': 443, 'city': 444, 'civil': 445, 'civilian': 446, 'claim': 447, 'class': 448, 'classic': 449, 'classroom': 450, 'clean': 451, 'clear': 452, 'clearly': 453, 'client': 454, 'climate': 455, 'climb': 456, 'clinic': 457, 'clinical': 458, 'clock': 459, 'close': 460, 'closely': 461, 'closer': 462, 'clothes': 463, 'clothing': 464, 'cloud': 465, 'club': 466, 'clue': 467, 'cluster': 468, 'coach': 469, 'coal': 470, 'coalition': 471, 'coast': 472, 'coat': 473, 'code': 474, 'coffee': 475, 'cognitive': 476, 'cold': 477, 'collapse': 478, 'colleague': 479, 'collect': 480, 'collection': 481, 'collective': 482, 'college': 483, 'colonial': 484, 'color': 485, 'column': 486, 'combination': 487, 'combine': 488, 'come': 489, 'comedy': 490, 'comfort': 491, 'comfortable': 492, 'command': 493, 'commander': 494, 'comment': 495, 'commercial': 496, 'commission': 497, 'commit': 498, 'commitment': 499, 'committee': 500, 'common': 501, 'communicate': 502, 'communication': 503, 'community': 504, 'company': 505, 'compare': 506, 'comparison': 507, 'compete': 508, 'competition': 509, 'competitive': 510, 'competitor': 511, 'complain': 512, 'complaint': 513, 'complete': 514, 'completely': 515, 'complex': 516, 'complicated': 517, 'component': 518, 'compose': 519, 'composition': 520, 'comprehensive': 521, 'computer': 522, 'concentrate': 523, 'concentration': 524, 'concept': 525, 'concern': 526, 'concerned': 527, 'concert': 528, 'conclude': 529, 'conclusion': 530, 'concrete': 531, 'condition': 532, 'conduct': 533, 'conference': 534, 'confidence': 535, 'confident': 536, 'confirm': 537, 'conflict': 538, 'confront': 539, 'confusion': 540, 'congressional': 541, 'connect': 542, 'connection': 543, 'consciousness': 544, 'consensus': 545, 'consequence': 546, 'conservative': 547, 'consider': 548, 'considerable': 549, 'consideration': 550, 'consist': 551, 'consistent': 552, 'constant': 553, 'constantly': 554, 'constitute': 555, 'constitutional': 556, 'construct': 557, 'construction': 558, 'consultant': 559, 'consume': 560, 'consumer': 561, 'consumption': 562, 'contact': 563, 'contain': 564, 'container': 565, 'contemporary': 566, 'content': 567, 'contest': 568, 'context': 569, 'continue': 570, 'continued': 571, 'contract': 572, 'contrast': 573, 'contribute': 574, 'contribution': 575, 'control': 576, 'controversial': 577, 'controversy': 578, 'convention': 579, 'conventional': 580, 'conversation': 581, 'convert': 582, 'conviction': 583, 'convince': 584, 'cook': 585, 'cookie': 586, 'cooking': 587, 'cool': 588, 'cooperation': 589, 'cop': 590, 'cope': 591, 'copy': 592, 'core': 593, 'corn': 594, 'corner': 595, 'corporate': 596, 'corporation': 597, 'correct': 598, 'correspondent': 599, 'cost': 600, 'cotton': 601, 'couch': 602, 'could': 603, 'council': 604, 'counselor': 605, 'count': 606, 'counter': 607, 'country': 608, 'county': 609, 'couple': 610, 'courage': 611, 'course': 612, 'court': 613, 'cousin': 614, 'cover': 615, 'coverage': 616, 'cow': 617, 'crack': 618, 'craft': 619, 'crash': 620, 'crazy': 621, 'cream': 622, 'create': 623, 'creation': 624, 'creative': 625, 'creature': 626, 'credit': 627, 'crew': 628, 'crime': 629, 'criminal': 630, 'crisis': 631, 'criteria': 632, 'critic': 633, 'critical': 634, 'criticism': 635, 'criticize': 636, 'crop': 637, 'cross': 638, 'crowd': 639, 'crucial': 640, 'cry': 641, 'cultural': 642, 'culture': 643, 'cup': 644, 'curious': 645, 'current': 646, 'currently': 647, 'curriculum': 648, 'custom': 649, 'customer': 650, 'cut': 651, 'cycle': 652, 'dad': 653, 'daily': 654, 'damage': 655, 'dance': 656, 'danger': 657, 'dangerous': 658, 'dare': 659, 'dark': 660, 'darkness': 661, 'data': 662, 'date': 663, 'daughter': 664, 'day': 665, 'dead': 666, 'deal': 667, 'dealer': 668, 'dear': 669, 'death': 670, 'debate': 671, 'debt': 672, 'decade': 673, 'decide': 674, 'decision': 675, 'deck': 676, 'declare': 677, 'decline': 678, 'decrease': 679, 'deep': 680, 'deeply': 681, 'deer': 682, 'defeat': 683, 'defend': 684, 'defendant': 685, 'defense': 686, 'defensive': 687, 'deficit': 688, 'define': 689, 'definitely': 690, 'definition': 691, 'degree': 692, 'delay': 693, 'deliver': 694, 'delivery': 695, 'demand': 696, 'democracy': 697, 'democratic': 698, 'demonstrate': 699, 'demonstration': 700, 'deny': 701, 'department': 702, 'depend': 703, 'dependent': 704, 'depending': 705, 'depict': 706, 'depression': 707, 'depth': 708, 'deputy': 709, 'derive': 710, 'describe': 711, 'description': 712, 'desert': 713, 'deserve': 714, 'design': 715, 'designer': 716, 'desire': 717, 'desk': 718, 'desperate': 719, 'despite': 720, 'destroy': 721, 'destruction': 722, 'detail': 723, 'detailed': 724, 'detect': 725, 'determine': 726, 'develop': 727, 'developing': 728, 'development': 729, 'device': 730, 'devote': 731, 'dialogue': 732, 'die': 733, 'diet': 734, 'differ': 735, 'difference': 736, 'different': 737, 'differently': 738, 'difficult': 739, 'difficulty': 740, 'dig': 741, 'digital': 742, 'dimension': 743, 'dining': 744, 'dinner': 745, 'direct': 746, 'direction': 747, 'directly': 748, 'director': 749, 'dirt': 750, 'dirty': 751, 'disability': 752, 'disagree': 753, 'disappear': 754, 'disaster': 755, 'discipline': 756, 'discourse': 757, 'discover': 758, 'discovery': 759, 'discrimination': 760, 'discuss': 761, 'discussion': 762, 'disease': 763, 'dish': 764, 'dismiss': 765, 'disorder': 766, 'display': 767, 'dispute': 768, 'distance': 769, 'distant': 770, 'distinct': 771, 'distinction': 772, 'distinguish': 773, 'distribute': 774, 'distribution': 775, 'district': 776, 'diverse': 777, 'diversity': 778, 'divide': 779, 'division': 780, 'divorce': 781, 'do': 782, 'doctor': 783, 'document': 784, 'dog': 785, 'domestic': 786, 'dominant': 787, 'dominate': 788, 'door': 789, 'double': 790, 'doubt': 791, 'down': 792, 'downtown': 793, 'dozen': 794, 'draft': 795, 'drag': 796, 'drama': 797, 'dramatic': 798, 'dramatically': 799, 'draw': 800, 'drawing': 801, 'dream': 802, 'dress': 803, 'drink': 804, 'drive': 805, 'driver': 806, 'drop': 807, 'drug': 808, 'dry': 809, 'due': 810, 'during': 811, 'dust': 812, 'duty': 813, 'each': 814, 'eager': 815, 'ear': 816, 'early': 817, 'earn': 818, 'earnings': 819, 'earth': 820, 'ease': 821, 'easily': 822, 'east': 823, 'eastern': 824, 'easy': 825, 'eat': 826, 'economic': 827, 'economics': 828, 'economist': 829, 'economy': 830, 'edge': 831, 'edition': 832, 'editor': 833, 'educate': 834, 'education': 835, 'educational': 836, 'educator': 837, 'effect': 838, 'effective': 839, 'effectively': 840, 'efficiency': 841, 'efficient': 842, 'effort': 843, 'egg': 844, 'eight': 845, 'either': 846, 'elderly': 847, 'elect': 848, 'election': 849, 'electric': 850, 'electricity': 851, 'electronic': 852, 'element': 853, 'elementary': 854, 'eliminate': 855, 'elite': 856, 'else': 857, 'elsewhere': 858, 'e-mail': 859, 'embrace': 860, 'emerge': 861, 'emergency': 862, 'emission': 863, 'emotion': 864, 'emotional': 865, 'emphasis': 866, 'emphasize': 867, 'employ': 868, 'employee': 869, 'employer': 870, 'employment': 871, 'empty': 872, 'enable': 873, 'encounter': 874, 'encourage': 875, 'end': 876, 'enemy': 877, 'energy': 878, 'enforcement': 879, 'engage': 880, 'engine': 881, 'engineer': 882, 'engineering': 883, 'enhance': 884, 'enjoy': 885, 'enormous': 886, 'enough': 887, 'ensure': 888, 'enter': 889, 'enterprise': 890, 'entertainment': 891, 'entire': 892, 'entirely': 893, 'entrance': 894, 'entry': 895, 'environment': 896, 'environmental': 897, 'episode': 898, 'equal': 899, 'equally': 900, 'equipment': 901, 'era': 902, 'error': 903, 'escape': 904, 'especially': 905, 'essay': 906, 'essential': 907, 'essentially': 908, 'establish': 909, 'establishment': 910, 'estate': 911, 'estimate': 912, 'etc': 913, 'ethics': 914, 'ethnic': 915, 'evaluate': 916, 'evaluation': 917, 'even': 918, 'evening': 919, 'event': 920, 'eventually': 921, 'ever': 922, 'every': 923, 'everybody': 924, 'everyday': 925, 'everyone': 926, 'everything': 927, 'everywhere': 928, 'evidence': 929, 'evolution': 930, 'evolve': 931, 'exact': 932, 'exactly': 933, 'examination': 934, 'examine': 935, 'example': 936, 'exceed': 937, 'excellent': 938, 'except': 939, 'exception': 940, 'exchange': 941, 'exciting': 942, 'executive': 943, 'exercise': 944, 'exhibit': 945, 'exhibition': 946, 'exist': 947, 'existence': 948, 'existing': 949, 'expand': 950, 'expansion': 951, 'expect': 952, 'expectation': 953, 'expense': 954, 'expensive': 955, 'experience': 956, 'experiment': 957, 'expert': 958, 'explain': 959, 'explanation': 960, 'explode': 961, 'explore': 962, 'explosion': 963, 'expose': 964, 'exposure': 965, 'express': 966, 'expression': 967, 'extend': 968, 'extension': 969, 'extensive': 970, 'extent': 971, 'external': 972, 'extra': 973, 'extraordinary': 974, 'extreme': 975, 'extremely': 976, 'eye': 977, 'fabric': 978, 'face': 979, 'facility': 980, 'fact': 981, 'factor': 982, 'factory': 983, 'faculty': 984, 'fade': 985, 'fail': 986, 'failure': 987, 'fair': 988, 'fairly': 989, 'faith': 990, 'fall': 991, 'false': 992, 'familiar': 993, 'family': 994, 'famous': 995, 'fan': 996, 'fantasy': 997, 'far': 998, 'farm': 999, 'farmer': 1000, 'fashion': 1001, 'fast': 1002, 'fat': 1003, 'fate': 1004, 'father': 1005, 'fault': 1006, 'favor': 1007, 'favorite': 1008, 'fear': 1009, 'feature': 1010, 'federal': 1011, 'fee': 1012, 'feed': 1013, 'feel': 1014, 'feeling': 1015, 'fellow': 1016, 'female': 1017, 'fence': 1018, 'few': 1019, 'fewer': 1020, 'fiber': 1021, 'fiction': 1022, 'field': 1023, 'fifteen': 1024, 'fifth': 1025, 'fifty': 1026, 'fight': 1027, 'fighter': 1028, 'fighting': 1029, 'figure': 1030, 'file': 1031, 'fill': 1032, 'film': 1033, 'final': 1034, 'finally': 1035, 'finance': 1036, 'financial': 1037, 'find': 1038, 'finding': 1039, 'fine': 1040, 'finger': 1041, 'finish': 1042, 'fire': 1043, 'firm': 1044, 'first': 1045, 'fish': 1046, 'fishing': 1047, 'fit': 1048, 'fitness': 1049, 'five': 1050, 'fix': 1051, 'flag': 1052, 'flame': 1053, 'flat': 1054, 'flavor': 1055, 'flee': 1056, 'flesh': 1057, 'flight': 1058, 'float': 1059, 'floor': 1060, 'flow': 1061, 'flower': 1062, 'fly': 1063, 'focus': 1064, 'folk': 1065, 'follow': 1066, 'following': 1067, 'food': 1068, 'foot': 1069, 'football': 1070, 'for': 1071, 'force': 1072, 'foreign': 1073, 'forest': 1074, 'forever': 1075, 'forget': 1076, 'form': 1077, 'formal': 1078, 'formation': 1079, 'former': 1080, 'formula': 1081, 'forth': 1082, 'fortune': 1083, 'forward': 1084, 'found': 1085, 'foundation': 1086, 'founder': 1087, 'four': 1088, 'fourth': 1089, 'frame': 1090, 'framework': 1091, 'free': 1092, 'freedom': 1093, 'freeze': 1094, 'frequency': 1095, 'frequent': 1096, 'frequently': 1097, 'fresh': 1098, 'friend': 1099, 'friendly': 1100, 'friendship': 1101, 'from': 1102, 'front': 1103, 'fruit': 1104, 'frustration': 1105, 'fuel': 1106, 'full': 1107, 'fully': 1108, 'fun': 1109, 'function': 1110, 'fund': 1111, 'fundamental': 1112, 'funding': 1113, 'funeral': 1114, 'funny': 1115, 'furniture': 1116, 'furthermore': 1117, 'future': 1118, 'gain': 1119, 'galaxy': 1120, 'gallery': 1121, 'game': 1122, 'gang': 1123, 'gap': 1124, 'garage': 1125, 'garden': 1126, 'garlic': 1127, 'gas': 1128, 'gate': 1129, 'gather': 1130, 'gay': 1131, 'gaze': 1132, 'gear': 1133, 'gender': 1134, 'gene': 1135, 'general': 1136, 'generally': 1137, 'generate': 1138, 'generation': 1139, 'genetic': 1140, 'gentleman': 1141, 'gently': 1142, 'gesture': 1143, 'get': 1144, 'ghost': 1145, 'giant': 1146, 'gift': 1147, 'gifted': 1148, 'girl': 1149, 'girlfriend': 1150, 'give': 1151, 'given': 1152, 'glad': 1153, 'glance': 1154, 'glass': 1155, 'global': 1156, 'glove': 1157, 'go': 1158, 'goal': 1159, 'gold': 1160, 'golden': 1161, 'golf': 1162, 'good': 1163, 'government': 1164, 'governor': 1165, 'grab': 1166, 'grade': 1167, 'gradually': 1168, 'graduate': 1169, 'grain': 1170, 'grand': 1171, 'grandfather': 1172, 'grandmother': 1173, 'grant': 1174, 'grass': 1175, 'grave': 1176, 'gray': 1177, 'great': 1178, 'greatest': 1179, 'green': 1180, 'grocery': 1181, 'ground': 1182, 'group': 1183, 'grow': 1184, 'growing': 1185, 'growth': 1186, 'guarantee': 1187, 'guard': 1188, 'guess': 1189, 'guest': 1190, 'guide': 1191, 'guideline': 1192, 'guilty': 1193, 'gun': 1194, 'guy': 1195, 'habit': 1196, 'habitat': 1197, 'hair': 1198, 'half': 1199, 'hall': 1200, 'hand': 1201, 'handful': 1202, 'handle': 1203, 'hang': 1204, 'happen': 1205, 'happy': 1206, 'hard': 1207, 'hardly': 1208, 'hat': 1209, 'hate': 1210, 'have': 1211, 'he': 1212, 'head': 1213, 'headline': 1214, 'headquarters': 1215, 'health': 1216, 'healthy': 1217, 'hear': 1218, 'hearing': 1219, 'heart': 1220, 'heat': 1221, 'heaven': 1222, 'heavily': 1223, 'heavy': 1224, 'heel': 1225, 'height': 1226, 'helicopter': 1227, 'hell': 1228, 'hello': 1229, 'help': 1230, 'helpful': 1231, 'her': 1232, 'here': 1233, 'heritage': 1234, 'hero': 1235, 'herself': 1236, 'hey': 1237, 'hi': 1238, 'hide': 1239, 'high': 1240, 'highlight': 1241, 'highly': 1242, 'highway': 1243, 'hill': 1244, 'him': 1245, 'himself': 1246, 'hip': 1247, 'hire': 1248, 'his': 1249, 'historian': 1250, 'historic': 1251, 'historical': 1252, 'history': 1253, 'hit': 1254, 'hold': 1255, 'hole': 1256, 'holiday': 1257, 'holy': 1258, 'home': 1259, 'homeless': 1260, 'honest': 1261, 'honey': 1262, 'honor': 1263, 'hope': 1264, 'horizon': 1265, 'horror': 1266, 'horse': 1267, 'hospital': 1268, 'host': 1269, 'hot': 1270, 'hotel': 1271, 'hour': 1272, 'house': 1273, 'household': 1274, 'housing': 1275, 'how': 1276, 'however': 1277, 'huge': 1278, 'human': 1279, 'humor': 1280, 'hundred': 1281, 'hungry': 1282, 'hunter': 1283, 'hunting': 1284, 'hurt': 1285, 'husband': 1286, 'hypothesis': 1287, 'ice': 1288, 'idea': 1289, 'ideal': 1290, 'identification': 1291, 'identify': 1292, 'identity': 1293, 'ie': 1294, 'if': 1295, 'ignore': 1296, 'ill': 1297, 'illegal': 1298, 'illness': 1299, 'illustrate': 1300, 'image': 1301, 'imagination': 1302, 'imagine': 1303, 'immediate': 1304, 'immediately': 1305, 'immigrant': 1306, 'immigration': 1307, 'impact': 1308, 'implement': 1309, 'implication': 1310, 'imply': 1311, 'importance': 1312, 'important': 1313, 'impose': 1314, 'impossible': 1315, 'impress': 1316, 'impression': 1317, 'impressive': 1318, 'improve': 1319, 'improvement': 1320, 'in': 1321, 'incentive': 1322, 'incident': 1323, 'include': 1324, 'including': 1325, 'income': 1326, 'incorporate': 1327, 'increase': 1328, 'increased': 1329, 'increasing': 1330, 'increasingly': 1331, 'incredible': 1332, 'indeed': 1333, 'independence': 1334, 'independent': 1335, 'index': 1336, 'indicate': 1337, 'indication': 1338, 'individual': 1339, 'industrial': 1340, 'industry': 1341, 'infant': 1342, 'infection': 1343, 'inflation': 1344, 'influence': 1345, 'inform': 1346, 'information': 1347, 'ingredient': 1348, 'initial': 1349, 'initially': 1350, 'initiative': 1351, 'injury': 1352, 'inner': 1353, 'innocent': 1354, 'inside': 1355, 'insight': 1356, 'insist': 1357, 'inspire': 1358, 'install': 1359, 'instance': 1360, 'instead': 1361, 'institution': 1362, 'institutional': 1363, 'instruction': 1364, 'instructor': 1365, 'instrument': 1366, 'insurance': 1367, 'intellectual': 1368, 'intelligence': 1369, 'intend': 1370, 'intense': 1371, 'intensity': 1372, 'intention': 1373, 'interaction': 1374, 'interest': 1375, 'interested': 1376, 'interesting': 1377, 'internal': 1378, 'international': 1379, 'interpret': 1380, 'interpretation': 1381, 'intervention': 1382, 'interview': 1383, 'into': 1384, 'introduce': 1385, 'introduction': 1386, 'invasion': 1387, 'invest': 1388, 'investigate': 1389, 'investigation': 1390, 'investigator': 1391, 'investment': 1392, 'investor': 1393, 'invite': 1394, 'involve': 1395, 'involved': 1396, 'involvement': 1397, 'iron': 1398, 'island': 1399, 'issue': 1400, 'it': 1401, 'item': 1402, 'its': 1403, 'itself': 1404, 'jacket': 1405, 'jail': 1406, 'jet': 1407, 'job': 1408, 'join': 1409, 'joint': 1410, 'joke': 1411, 'journal': 1412, 'journalist': 1413, 'journey': 1414, 'joy': 1415, 'judge': 1416, 'judgment': 1417, 'juice': 1418, 'jump': 1419, 'junior': 1420, 'jury': 1421, 'just': 1422, 'justice': 1423, 'justify': 1424, 'keep': 1425, 'key': 1426, 'kick': 1427, 'kid': 1428, 'kill': 1429, 'killer': 1430, 'killing': 1431, 'kind': 1432, 'king': 1433, 'kiss': 1434, 'kitchen': 1435, 'knee': 1436, 'knife': 1437, 'knock': 1438, 'know': 1439, 'knowledge': 1440, 'lab': 1441, 'label': 1442, 'labor': 1443, 'laboratory': 1444, 'lack': 1445, 'lady': 1446, 'lake': 1447, 'land': 1448, 'landscape': 1449, 'language': 1450, 'lap': 1451, 'large': 1452, 'largely': 1453, 'last': 1454, 'late': 1455, 'later': 1456, 'latter': 1457, 'laugh': 1458, 'launch': 1459, 'law': 1460, 'lawn': 1461, 'lawsuit': 1462, 'lawyer': 1463, 'lay': 1464, 'layer': 1465, 'lead': 1466, 'leader': 1467, 'leadership': 1468, 'leading': 1469, 'leaf': 1470, 'league': 1471, 'lean': 1472, 'learn': 1473, 'learning': 1474, 'least': 1475, 'leather': 1476, 'leave': 1477, 'left': 1478, 'leg': 1479, 'legacy': 1480, 'legal': 1481, 'legend': 1482, 'legislation': 1483, 'legitimate': 1484, 'lemon': 1485, 'length': 1486, 'less': 1487, 'lesson': 1488, 'let': 1489, 'letter': 1490, 'level': 1491, 'liberal': 1492, 'library': 1493, 'license': 1494, 'lie': 1495, 'life': 1496, 'lifestyle': 1497, 'lifetime': 1498, 'lift': 1499, 'light': 1500, 'like': 1501, 'likely': 1502, 'limit': 1503, 'limitation': 1504, 'limited': 1505, 'line': 1506, 'link': 1507, 'lip': 1508, 'list': 1509, 'listen': 1510, 'literally': 1511, 'literary': 1512, 'literature': 1513, 'little': 1514, 'live': 1515, 'living': 1516, 'load': 1517, 'loan': 1518, 'local': 1519, 'locate': 1520, 'location': 1521, 'lock': 1522, 'long': 1523, 'long-term': 1524, 'look': 1525, 'loose': 1526, 'lose': 1527, 'loss': 1528, 'lost': 1529, 'lot': 1530, 'lots': 1531, 'loud': 1532, 'love': 1533, 'lovely': 1534, 'lover': 1535, 'low': 1536, 'lower': 1537, 'luck': 1538, 'lucky': 1539, 'lunch': 1540, 'lung': 1541, 'machine': 1542, 'mad': 1543, 'magazine': 1544, 'mail': 1545, 'main': 1546, 'mainly': 1547, 'maintain': 1548, 'maintenance': 1549, 'major': 1550, 'majority': 1551, 'make': 1552, 'maker': 1553, 'makeup': 1554, 'male': 1555, 'mall': 1556, 'man': 1557, 'manage': 1558, 'management': 1559, 'manager': 1560, 'manner': 1561, 'manufacturer': 1562, 'manufacturing': 1563, 'many': 1564, 'map': 1565, 'margin': 1566, 'mark': 1567, 'market': 1568, 'marketing': 1569, 'marriage': 1570, 'married': 1571, 'marry': 1572, 'mask': 1573, 'mass': 1574, 'massive': 1575, 'master': 1576, 'match': 1577, 'material': 1578, 'math': 1579, 'matter': 1580, 'may': 1581, 'maybe': 1582, 'mayor': 1583, 'me': 1584, 'meal': 1585, 'mean': 1586, 'meaning': 1587, 'meanwhile': 1588, 'measure': 1589, 'measurement': 1590, 'meat': 1591, 'mechanism': 1592, 'media': 1593, 'medical': 1594, 'medication': 1595, 'medicine': 1596, 'medium': 1597, 'meet': 1598, 'meeting': 1599, 'member': 1600, 'membership': 1601, 'memory': 1602, 'mental': 1603, 'mention': 1604, 'menu': 1605, 'mere': 1606, 'merely': 1607, 'mess': 1608, 'message': 1609, 'metal': 1610, 'meter': 1611, 'method': 1612, 'middle': 1613, 'might': 1614, 'military': 1615, 'milk': 1616, 'million': 1617, 'mind': 1618, 'mine': 1619, 'minister': 1620, 'minor': 1621, 'minority': 1622, 'minute': 1623, 'miracle': 1624, 'mirror': 1625, 'miss': 1626, 'missile': 1627, 'mission': 1628, 'mistake': 1629, 'mix': 1630, 'mixture': 1631, 'mm-hmm': 1632, 'mode': 1633, 'model': 1634, 'moderate': 1635, 'modern': 1636, 'modest': 1637, 'mom': 1638, 'moment': 1639, 'money': 1640, 'monitor': 1641, 'month': 1642, 'mood': 1643, 'moon': 1644, 'moral': 1645, 'more': 1646, 'moreover': 1647, 'morning': 1648, 'mortgage': 1649, 'most': 1650, 'mostly': 1651, 'mother': 1652, 'motion': 1653, 'motivation': 1654, 'motor': 1655, 'mount': 1656, 'mountain': 1657, 'mouse': 1658, 'mouth': 1659, 'move': 1660, 'movement': 1661, 'movie': 1662, 'much': 1663, 'multiple': 1664, 'murder': 1665, 'muscle': 1666, 'museum': 1667, 'music': 1668, 'musical': 1669, 'musician': 1670, 'must': 1671, 'mutual': 1672, 'my': 1673, 'myself': 1674, 'mystery': 1675, 'myth': 1676, 'naked': 1677, 'name': 1678, 'narrative': 1679, 'narrow': 1680, 'nation': 1681, 'national': 1682, 'native': 1683, 'natural': 1684, 'naturally': 1685, 'nature': 1686, 'near': 1687, 'nearby': 1688, 'nearly': 1689, 'necessarily': 1690, 'necessary': 1691, 'neck': 1692, 'need': 1693, 'negative': 1694, 'negotiate': 1695, 'negotiation': 1696, 'neighbor': 1697, 'neighborhood': 1698, 'neither': 1699, 'nerve': 1700, 'nervous': 1701, 'net': 1702, 'network': 1703, 'never': 1704, 'nevertheless': 1705, 'new': 1706, 'newly': 1707, 'news': 1708, 'newspaper': 1709, 'next': 1710, 'nice': 1711, 'night': 1712, 'nine': 1713, 'no': 1714, 'nobody': 1715, 'nod': 1716, 'noise': 1717, 'nomination': 1718, 'none': 1719, 'nonetheless': 1720, 'nor': 1721, 'normal': 1722, 'normally': 1723, 'north': 1724, 'northern': 1725, 'nose': 1726, 'not': 1727, 'note': 1728, 'nothing': 1729, 'notice': 1730, 'notion': 1731, 'novel': 1732, 'now': 1733, 'nowhere': 1734, 'nuclear': 1735, 'number': 1736, 'numerous': 1737, 'nurse': 1738, 'nut': 1739, 'object': 1740, 'objective': 1741, 'obligation': 1742, 'observation': 1743, 'observe': 1744, 'observer': 1745, 'obtain': 1746, 'obvious': 1747, 'obviously': 1748, 'occasion': 1749, 'occasionally': 1750, 'occupation': 1751, 'occupy': 1752, 'occur': 1753, 'ocean': 1754, 'odd': 1755, 'odds': 1756, 'of': 1757, 'off': 1758, 'offense': 1759, 'offensive': 1760, 'offer': 1761, 'office': 1762, 'officer': 1763, 'official': 1764, 'often': 1765, 'oh': 1766, 'oil': 1767, 'ok': 1768, 'okay': 1769, 'old': 1770, 'on': 1771, 'once': 1772, 'one': 1773, 'ongoing': 1774, 'onion': 1775, 'online': 1776, 'only': 1777, 'onto': 1778, 'open': 1779, 'opening': 1780, 'operate': 1781, 'operating': 1782, 'operation': 1783, 'operator': 1784, 'opinion': 1785, 'opponent': 1786, 'opportunity': 1787, 'oppose': 1788, 'opposite': 1789, 'opposition': 1790, 'option': 1791, 'or': 1792, 'orange': 1793, 'order': 1794, 'ordinary': 1795, 'organic': 1796, 'organization': 1797, 'organize': 1798, 'orientation': 1799, 'origin': 1800, 'original': 1801, 'originally': 1802, 'other': 1803, 'others': 1804, 'otherwise': 1805, 'ought': 1806, 'our': 1807, 'ourselves': 1808, 'out': 1809, 'outcome': 1810, 'outside': 1811, 'oven': 1812, 'over': 1813, 'overall': 1814, 'overcome': 1815, 'overlook': 1816, 'owe': 1817, 'own': 1818, 'owner': 1819, 'pace': 1820, 'pack': 1821, 'package': 1822, 'page': 1823, 'pain': 1824, 'painful': 1825, 'paint': 1826, 'painter': 1827, 'painting': 1828, 'pair': 1829, 'pale': 1830, 'palm': 1831, 'pan': 1832, 'panel': 1833, 'pant': 1834, 'paper': 1835, 'parent': 1836, 'park': 1837, 'parking': 1838, 'part': 1839, 'participant': 1840, 'participate': 1841, 'participation': 1842, 'particular': 1843, 'particularly': 1844, 'partly': 1845, 'partner': 1846, 'partnership': 1847, 'party': 1848, 'pass': 1849, 'passage': 1850, 'passenger': 1851, 'passion': 1852, 'past': 1853, 'patch': 1854, 'path': 1855, 'patient': 1856, 'pattern': 1857, 'pause': 1858, 'pay': 1859, 'payment': 1860, 'peace': 1861, 'peak': 1862, 'peer': 1863, 'penalty': 1864, 'people': 1865, 'pepper': 1866, 'per': 1867, 'perceive': 1868, 'percentage': 1869, 'perception': 1870, 'perfect': 1871, 'perfectly': 1872, 'perform': 1873, 'performance': 1874, 'perhaps': 1875, 'period': 1876, 'permanent': 1877, 'permission': 1878, 'permit': 1879, 'person': 1880, 'personal': 1881, 'personality': 1882, 'personally': 1883, 'personnel': 1884, 'perspective': 1885, 'persuade': 1886, 'pet': 1887, 'phase': 1888, 'phenomenon': 1889, 'philosophy': 1890, 'phone': 1891, 'photo': 1892, 'photograph': 1893, 'photographer': 1894, 'phrase': 1895, 'physical': 1896, 'physically': 1897, 'physician': 1898, 'piano': 1899, 'pick': 1900, 'picture': 1901, 'pie': 1902, 'piece': 1903, 'pile': 1904, 'pilot': 1905, 'pine': 1906, 'pink': 1907, 'pipe': 1908, 'pitch': 1909, 'place': 1910, 'plan': 1911, 'plane': 1912, 'planet': 1913, 'planning': 1914, 'plant': 1915, 'plastic': 1916, 'plate': 1917, 'platform': 1918, 'play': 1919, 'player': 1920, 'please': 1921, 'pleasure': 1922, 'plenty': 1923, 'plot': 1924, 'plus': 1925, 'pocket': 1926, 'poem': 1927, 'poet': 1928, 'poetry': 1929, 'point': 1930, 'pole': 1931, 'police': 1932, 'policy': 1933, 'political': 1934, 'politically': 1935, 'politician': 1936, 'politics': 1937, 'poll': 1938, 'pollution': 1939, 'pool': 1940, 'poor': 1941, 'pop': 1942, 'popular': 1943, 'population': 1944, 'porch': 1945, 'port': 1946, 'portion': 1947, 'portrait': 1948, 'portray': 1949, 'pose': 1950, 'position': 1951, 'positive': 1952, 'possess': 1953, 'possibility': 1954, 'possible': 1955, 'possibly': 1956, 'post': 1957, 'pot': 1958, 'potato': 1959, 'potential': 1960, 'potentially': 1961, 'pound': 1962, 'pour': 1963, 'poverty': 1964, 'powder': 1965, 'power': 1966, 'powerful': 1967, 'practical': 1968, 'practice': 1969, 'pray': 1970, 'prayer': 1971, 'precisely': 1972, 'predict': 1973, 'prefer': 1974, 'preference': 1975, 'pregnancy': 1976, 'pregnant': 1977, 'preparation': 1978, 'prepare': 1979, 'prescription': 1980, 'presence': 1981, 'present': 1982, 'presentation': 1983, 'preserve': 1984, 'president': 1985, 'presidential': 1986, 'press': 1987, 'pressure': 1988, 'pretend': 1989, 'pretty': 1990, 'prevent': 1991, 'previous': 1992, 'previously': 1993, 'price': 1994, 'pride': 1995, 'priest': 1996, 'primarily': 1997, 'primary': 1998, 'prime': 1999, 'principal': 2000, 'principle': 2001, 'print': 2002, 'prior': 2003, 'priority': 2004, 'prison': 2005, 'prisoner': 2006, 'privacy': 2007, 'private': 2008, 'probably': 2009, 'problem': 2010, 'procedure': 2011, 'proceed': 2012, 'process': 2013, 'produce': 2014, 'producer': 2015, 'product': 2016, 'production': 2017, 'profession': 2018, 'professional': 2019, 'professor': 2020, 'profile': 2021, 'profit': 2022, 'progress': 2023, 'project': 2024, 'prominent': 2025, 'promise': 2026, 'promote': 2027, 'prompt': 2028, 'proof': 2029, 'proper': 2030, 'properly': 2031, 'property': 2032, 'proportion': 2033, 'proposal': 2034, 'propose': 2035, 'proposed': 2036, 'prosecutor': 2037, 'prospect': 2038, 'protect': 2039, 'protection': 2040, 'protein': 2041, 'protest': 2042, 'proud': 2043, 'prove': 2044, 'provide': 2045, 'provider': 2046, 'province': 2047, 'provision': 2048, 'psychological': 2049, 'psychologist': 2050, 'psychology': 2051, 'public': 2052, 'publication': 2053, 'publicly': 2054, 'publish': 2055, 'publisher': 2056, 'pull': 2057, 'punishment': 2058, 'purchase': 2059, 'pure': 2060, 'purpose': 2061, 'pursue': 2062, 'push': 2063, 'put': 2064, 'qualify': 2065, 'quality': 2066, 'quarter': 2067, 'quarterback': 2068, 'question': 2069, 'quick': 2070, 'quickly': 2071, 'quiet': 2072, 'quietly': 2073, 'quit': 2074, 'quite': 2075, 'quote': 2076, 'race': 2077, 'racial': 2078, 'radical': 2079, 'radio': 2080, 'rail': 2081, 'rain': 2082, 'raise': 2083, 'range': 2084, 'rank': 2085, 'rapid': 2086, 'rapidly': 2087, 'rare': 2088, 'rarely': 2089, 'rate': 2090, 'rather': 2091, 'rating': 2092, 'ratio': 2093, 'raw': 2094, 'reach': 2095, 'react': 2096, 'reaction': 2097, 'read': 2098, 'reader': 2099, 'reading': 2100, 'ready': 2101, 'real': 2102, 'reality': 2103, 'realize': 2104, 'really': 2105, 'reason': 2106, 'reasonable': 2107, 'recall': 2108, 'receive': 2109, 'recent': 2110, 'recently': 2111, 'recipe': 2112, 'recognition': 2113, 'recognize': 2114, 'recommend': 2115, 'recommendation': 2116, 'record': 2117, 'recording': 2118, 'recover': 2119, 'recovery': 2120, 'recruit': 2121, 'red': 2122, 'reduce': 2123, 'reduction': 2124, 'refer': 2125, 'reference': 2126, 'reflect': 2127, 'reflection': 2128, 'reform': 2129, 'refugee': 2130, 'refuse': 2131, 'regard': 2132, 'regarding': 2133, 'regardless': 2134, 'regime': 2135, 'region': 2136, 'regional': 2137, 'register': 2138, 'regular': 2139, 'regularly': 2140, 'regulate': 2141, 'regulation': 2142, 'reinforce': 2143, 'reject': 2144, 'relate': 2145, 'relation': 2146, 'relationship': 2147, 'relative': 2148, 'relatively': 2149, 'relax': 2150, 'release': 2151, 'relevant': 2152, 'relief': 2153, 'religion': 2154, 'religious': 2155, 'rely': 2156, 'remain': 2157, 'remaining': 2158, 'remarkable': 2159, 'remember': 2160, 'remind': 2161, 'remote': 2162, 'remove': 2163, 'repeat': 2164, 'repeatedly': 2165, 'replace': 2166, 'reply': 2167, 'report': 2168, 'reporter': 2169, 'represent': 2170, 'representation': 2171, 'representative': 2172, 'reputation': 2173, 'request': 2174, 'require': 2175, 'requirement': 2176, 'research': 2177, 'researcher': 2178, 'resemble': 2179, 'reservation': 2180, 'resident': 2181, 'resist': 2182, 'resistance': 2183, 'resolution': 2184, 'resolve': 2185, 'resort': 2186, 'resource': 2187, 'respect': 2188, 'respond': 2189, 'respondent': 2190, 'response': 2191, 'responsibility': 2192, 'responsible': 2193, 'rest': 2194, 'restaurant': 2195, 'restore': 2196, 'restriction': 2197, 'result': 2198, 'retain': 2199, 'retire': 2200, 'retirement': 2201, 'return': 2202, 'reveal': 2203, 'revenue': 2204, 'review': 2205, 'revolution': 2206, 'rhythm': 2207, 'rice': 2208, 'rich': 2209, 'rid': 2210, 'ride': 2211, 'rifle': 2212, 'right': 2213, 'ring': 2214, 'rise': 2215, 'risk': 2216, 'river': 2217, 'road': 2218, 'rock': 2219, 'role': 2220, 'roll': 2221, 'romantic': 2222, 'roof': 2223, 'room': 2224, 'root': 2225, 'rope': 2226, 'rose': 2227, 'rough': 2228, 'roughly': 2229, 'round': 2230, 'route': 2231, 'routine': 2232, 'row': 2233, 'rub': 2234, 'rule': 2235, 'run': 2236, 'running': 2237, 'rural': 2238, 'rush': 2239, 'sacred': 2240, 'sad': 2241, 'safe': 2242, 'safety': 2243, 'sake': 2244, 'salad': 2245, 'salary': 2246, 'sale': 2247, 'sales': 2248, 'salt': 2249, 'same': 2250, 'sample': 2251, 'sanction': 2252, 'sand': 2253, 'satellite': 2254, 'satisfaction': 2255, 'satisfy': 2256, 'sauce': 2257, 'save': 2258, 'saving': 2259, 'say': 2260, 'scale': 2261, 'scandal': 2262, 'scared': 2263, 'scenario': 2264, 'scene': 2265, 'schedule': 2266, 'scheme': 2267, 'scholar': 2268, 'scholarship': 2269, 'school': 2270, 'science': 2271, 'scientific': 2272, 'scientist': 2273, 'scope': 2274, 'score': 2275, 'scream': 2276, 'screen': 2277, 'script': 2278, 'sea': 2279, 'search': 2280, 'season': 2281, 'seat': 2282, 'second': 2283, 'secret': 2284, 'secretary': 2285, 'section': 2286, 'sector': 2287, 'secure': 2288, 'security': 2289, 'see': 2290, 'seed': 2291, 'seek': 2292, 'seem': 2293, 'segment': 2294, 'seize': 2295, 'select': 2296, 'selection': 2297, 'self': 2298, 'sell': 2299, 'senator': 2300, 'send': 2301, 'senior': 2302, 'sense': 2303, 'sensitive': 2304, 'sentence': 2305, 'separate': 2306, 'sequence': 2307, 'series': 2308, 'serious': 2309, 'seriously': 2310, 'serve': 2311, 'service': 2312, 'session': 2313, 'set': 2314, 'setting': 2315, 'settle': 2316, 'settlement': 2317, 'seven': 2318, 'several': 2319, 'severe': 2320, 'sex': 2321, 'sexual': 2322, 'shade': 2323, 'shadow': 2324, 'shake': 2325, 'shall': 2326, 'shape': 2327, 'share': 2328, 'sharp': 2329, 'she': 2330, 'sheet': 2331, 'shelf': 2332, 'shell': 2333, 'shelter': 2334, 'shift': 2335, 'shine': 2336, 'ship': 2337, 'shirt': 2338, 'shit': 2339, 'shock': 2340, 'shoe': 2341, 'shoot': 2342, 'shooting': 2343, 'shop': 2344, 'shopping': 2345, 'shore': 2346, 'short': 2347, 'shortly': 2348, 'shot': 2349, 'should': 2350, 'shoulder': 2351, 'shout': 2352, 'show': 2353, 'shower': 2354, 'shrug': 2355, 'shut': 2356, 'sick': 2357, 'side': 2358, 'sigh': 2359, 'sight': 2360, 'sign': 2361, 'signal': 2362, 'significance': 2363, 'significant': 2364, 'significantly': 2365, 'silence': 2366, 'silent': 2367, 'silver': 2368, 'similar': 2369, 'similarly': 2370, 'simple': 2371, 'simply': 2372, 'sin': 2373, 'since': 2374, 'sing': 2375, 'singer': 2376, 'single': 2377, 'sink': 2378, 'sir': 2379, 'sister': 2380, 'sit': 2381, 'site': 2382, 'situation': 2383, 'six': 2384, 'size': 2385, 'ski': 2386, 'skill': 2387, 'skin': 2388, 'sky': 2389, 'slave': 2390, 'sleep': 2391, 'slice': 2392, 'slide': 2393, 'slight': 2394, 'slightly': 2395, 'slip': 2396, 'slow': 2397, 'slowly': 2398, 'small': 2399, 'smart': 2400, 'smell': 2401, 'smile': 2402, 'smoke': 2403, 'smooth': 2404, 'snap': 2405, 'snow': 2406, 'so': 2407, 'so-called': 2408, 'soccer': 2409, 'social': 2410, 'society': 2411, 'soft': 2412, 'software': 2413, 'soil': 2414, 'solar': 2415, 'soldier': 2416, 'solid': 2417, 'solution': 2418, 'solve': 2419, 'some': 2420, 'somebody': 2421, 'somehow': 2422, 'someone': 2423, 'something': 2424, 'sometimes': 2425, 'somewhat': 2426, 'somewhere': 2427, 'son': 2428, 'song': 2429, 'soon': 2430, 'sophisticated': 2431, 'sorry': 2432, 'sort': 2433, 'soul': 2434, 'sound': 2435, 'soup': 2436, 'source': 2437, 'south': 2438, 'southern': 2439, 'space': 2440, 'speak': 2441, 'speaker': 2442, 'special': 2443, 'specialist': 2444, 'species': 2445, 'specific': 2446, 'specifically': 2447, 'speech': 2448, 'speed': 2449, 'spend': 2450, 'spending': 2451, 'spin': 2452, 'spirit': 2453, 'spiritual': 2454, 'split': 2455, 'spokesman': 2456, 'sport': 2457, 'spot': 2458, 'spread': 2459, 'spring': 2460, 'square': 2461, 'squeeze': 2462, 'stability': 2463, 'stable': 2464, 'staff': 2465, 'stage': 2466, 'stair': 2467, 'stake': 2468, 'stand': 2469, 'standard': 2470, 'standing': 2471, 'star': 2472, 'stare': 2473, 'start': 2474, 'state': 2475, 'statement': 2476, 'station': 2477, 'statistics': 2478, 'status': 2479, 'stay': 2480, 'steady': 2481, 'steal': 2482, 'steel': 2483, 'step': 2484, 'stick': 2485, 'still': 2486, 'stir': 2487, 'stock': 2488, 'stomach': 2489, 'stone': 2490, 'stop': 2491, 'storage': 2492, 'store': 2493, 'storm': 2494, 'story': 2495, 'straight': 2496, 'strange': 2497, 'stranger': 2498, 'strategic': 2499, 'strategy': 2500, 'stream': 2501, 'street': 2502, 'strength': 2503, 'strengthen': 2504, 'stress': 2505, 'stretch': 2506, 'strike': 2507, 'string': 2508, 'strip': 2509, 'stroke': 2510, 'strong': 2511, 'strongly': 2512, 'structure': 2513, 'struggle': 2514, 'student': 2515, 'studio': 2516, 'study': 2517, 'stuff': 2518, 'stupid': 2519, 'style': 2520, 'subject': 2521, 'submit': 2522, 'subsequent': 2523, 'substance': 2524, 'substantial': 2525, 'succeed': 2526, 'success': 2527, 'successful': 2528, 'successfully': 2529, 'such': 2530, 'sudden': 2531, 'suddenly': 2532, 'sue': 2533, 'suffer': 2534, 'sufficient': 2535, 'sugar': 2536, 'suggest': 2537, 'suggestion': 2538, 'suicide': 2539, 'suit': 2540, 'summer': 2541, 'summit': 2542, 'sun': 2543, 'super': 2544, 'supply': 2545, 'support': 2546, 'supporter': 2547, 'suppose': 2548, 'supposed': 2549, 'sure': 2550, 'surely': 2551, 'surface': 2552, 'surgery': 2553, 'surprise': 2554, 'surprised': 2555, 'surprising': 2556, 'surprisingly': 2557, 'surround': 2558, 'survey': 2559, 'survival': 2560, 'survive': 2561, 'survivor': 2562, 'suspect': 2563, 'sustain': 2564, 'swear': 2565, 'sweep': 2566, 'sweet': 2567, 'swim': 2568, 'swing': 2569, 'switch': 2570, 'symbol': 2571, 'symptom': 2572, 'system': 2573, 'table': 2574, 'tablespoon': 2575, 'tactic': 2576, 'tail': 2577, 'take': 2578, 'tale': 2579, 'talent': 2580, 'talk': 2581, 'tall': 2582, 'tank': 2583, 'tap': 2584, 'tape': 2585, 'target': 2586, 'task': 2587, 'taste': 2588, 'tax': 2589, 'taxpayer': 2590, 'tea': 2591, 'teach': 2592, 'teacher': 2593, 'teaching': 2594, 'team': 2595, 'tear': 2596, 'teaspoon': 2597, 'technical': 2598, 'technique': 2599, 'technology': 2600, 'teen': 2601, 'teenager': 2602, 'telephone': 2603, 'telescope': 2604, 'television': 2605, 'tell': 2606, 'temperature': 2607, 'temporary': 2608, 'ten': 2609, 'tend': 2610, 'tendency': 2611, 'tennis': 2612, 'tension': 2613, 'tent': 2614, 'term': 2615, 'terms': 2616, 'terrible': 2617, 'territory': 2618, 'terror': 2619, 'terrorism': 2620, 'terrorist': 2621, 'test': 2622, 'testify': 2623, 'testimony': 2624, 'testing': 2625, 'text': 2626, 'than': 2627, 'thank': 2628, 'thanks': 2629, 'that': 2630, 'the': 2631, 'theater': 2632, 'their': 2633, 'them': 2634, 'theme': 2635, 'themselves': 2636, 'then': 2637, 'theory': 2638, 'therapy': 2639, 'there': 2640, 'therefore': 2641, 'they': 2642, 'thick': 2643, 'thin': 2644, 'thing': 2645, 'think': 2646, 'thinking': 2647, 'third': 2648, 'thirty': 2649, 'this': 2650, 'though': 2651, 'thought': 2652, 'thousand': 2653, 'threat': 2654, 'threaten': 2655, 'three': 2656, 'throat': 2657, 'through': 2658, 'throughout': 2659, 'throw': 2660, 'thus': 2661, 'ticket': 2662, 'tie': 2663, 'tight': 2664, 'time': 2665, 'tiny': 2666, 'tip': 2667, 'tire': 2668, 'tired': 2669, 'tissue': 2670, 'title': 2671, 'to': 2672, 'tobacco': 2673, 'today': 2674, 'toe': 2675, 'together': 2676, 'tomato': 2677, 'tomorrow': 2678, 'tone': 2679, 'tongue': 2680, 'tonight': 2681, 'too': 2682, 'tool': 2683, 'tooth': 2684, 'top': 2685, 'topic': 2686, 'toss': 2687, 'total': 2688, 'totally': 2689, 'touch': 2690, 'tough': 2691, 'tour': 2692, 'tourist': 2693, 'tournament': 2694, 'toward': 2695, 'towards': 2696, 'tower': 2697, 'town': 2698, 'toy': 2699, 'trace': 2700, 'track': 2701, 'trade': 2702, 'tradition': 2703, 'traditional': 2704, 'traffic': 2705, 'tragedy': 2706, 'trail': 2707, 'train': 2708, 'training': 2709, 'transfer': 2710, 'transform': 2711, 'transformation': 2712, 'transition': 2713, 'translate': 2714, 'transportation': 2715, 'travel': 2716, 'treat': 2717, 'treatment': 2718, 'treaty': 2719, 'tree': 2720, 'tremendous': 2721, 'trend': 2722, 'trial': 2723, 'tribe': 2724, 'trick': 2725, 'trip': 2726, 'troop': 2727, 'trouble': 2728, 'truck': 2729, 'true': 2730, 'truly': 2731, 'trust': 2732, 'truth': 2733, 'try': 2734, 'tube': 2735, 'tunnel': 2736, 'turn': 2737, 'twelve': 2738, 'twenty': 2739, 'twice': 2740, 'twin': 2741, 'two': 2742, 'type': 2743, 'typical': 2744, 'typically': 2745, 'ugly': 2746, 'ultimate': 2747, 'ultimately': 2748, 'unable': 2749, 'uncle': 2750, 'under': 2751, 'undergo': 2752, 'understand': 2753, 'understanding': 2754, 'unfortunately': 2755, 'uniform': 2756, 'union': 2757, 'unique': 2758, 'unit': 2759, 'universal': 2760, 'universe': 2761, 'university': 2762, 'unknown': 2763, 'unless': 2764, 'unlike': 2765, 'unlikely': 2766, 'until': 2767, 'unusual': 2768, 'up': 2769, 'upper': 2770, 'urban': 2771, 'urge': 2772, 'us': 2773, 'use': 2774, 'used': 2775, 'useful': 2776, 'user': 2777, 'usual': 2778, 'usually': 2779, 'utility': 2780, 'vacation': 2781, 'valley': 2782, 'valuable': 2783, 'value': 2784, 'variable': 2785, 'variation': 2786, 'variety': 2787, 'various': 2788, 'vary': 2789, 'vast': 2790, 'vegetable': 2791, 'vehicle': 2792, 'venture': 2793, 'version': 2794, 'versus': 2795, 'very': 2796, 'vessel': 2797, 'veteran': 2798, 'via': 2799, 'victim': 2800, 'victory': 2801, 'video': 2802, 'view': 2803, 'viewer': 2804, 'village': 2805, 'violate': 2806, 'violation': 2807, 'violence': 2808, 'violent': 2809, 'virtually': 2810, 'virtue': 2811, 'virus': 2812, 'visible': 2813, 'vision': 2814, 'visit': 2815, 'visitor': 2816, 'visual': 2817, 'vital': 2818, 'voice': 2819, 'volume': 2820, 'volunteer': 2821, 'vote': 2822, 'voter': 2823, 'vs': 2824, 'vulnerable': 2825, 'wage': 2826, 'wait': 2827, 'wake': 2828, 'walk': 2829, 'wall': 2830, 'wander': 2831, 'want': 2832, 'war': 2833, 'warm': 2834, 'warn': 2835, 'warning': 2836, 'wash': 2837, 'waste': 2838, 'watch': 2839, 'water': 2840, 'wave': 2841}\n",
            "2842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKfWnApvOoE7"
      },
      "source": [
        "# Split train dataset into train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfhSPF5jOWb7"
      },
      "source": [
        "# 8\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.3)\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7hsdLoCO7uB"
      },
      "source": [
        "# Import BERT Model and BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1kY3gZjO2RE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "4cdacd5286384965a4241c45003b0260",
            "c5b9e0e57f864455a4709bae62fc1d8e",
            "61a6dc466e52477ea0da28e71ab5eb19",
            "04563fd5dce9421ab3a0391d950f48d4",
            "488fac3346ae4653ba9d22e8570eda81",
            "7086d1e7f9e24713978a9e4de77b9998",
            "738626a884bd45658d0b553751a622e5",
            "234f9a29556541a398bd3cdbdfc91363",
            "8963551c8f894ca8a1aace9b5184f82a",
            "453e5421d9924687a7484b06c4825ea3",
            "a4e441d94cb44d24918198c2e156865d",
            "e98997f8b528459c86acdd01dcca3080",
            "8d1cd667f48f4a4e8f5c9372991ef843",
            "ff32f251207845fab3dd6481e7564fa7",
            "4136eac3dba24c1a81945fe0ef677e91",
            "9a1a015354144498b75ddb35312eff80",
            "e539952280fa490cb29a16a386b1eea5",
            "c0e190b0e5a1465c982b404eb6e13c6b",
            "a9a6244799f446c4bc4d78c033742653",
            "5ed0acd64356410d9b40ebcf07cf024b",
            "cbd646674ada4ef692bb656eb4aa8598",
            "ad8a8fcb244a4691860bfe0cb5aeaf8c",
            "4ddc272fd62e41cb827c87c6f7bd8a1c",
            "9811cd06dbe64cc1a8c94c56f05e89a4"
          ]
        },
        "outputId": "9d1034e1-82cf-48c6-8cb1-d8e15eb557be"
      },
      "source": [
        "# 9\n",
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cdacd5286384965a4241c45003b0260",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8963551c8f894ca8a1aace9b5184f82a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e539952280fa490cb29a16a386b1eea5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zOKeOMeO-DT"
      },
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAH73n39PHLw",
        "outputId": "dbffefad-56e1-4a7a-c142-b306c1a04ba9"
      },
      "source": [
        "# output\n",
        "print(sent_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIYaWI_Prg8"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "yKwbpeN_PMiu",
        "outputId": "2bf7c087-e879-4039-e2df-cb8233b57abd"
      },
      "source": [
        "# 10\n",
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7aa9ddb7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXcswEIRPvGe"
      },
      "source": [
        "# 11\n",
        "max_seq_len = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5S7DWaP2t6"
      },
      "source": [
        "# 12\n",
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsm8bkRZQTw9"
      },
      "source": [
        "# Convert Integer Sequences to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR-lXwmzQPd6",
        "outputId": "bf666d6e-aa3f-44ab-8097-fd88322dfbca"
      },
      "source": [
        "# 13\n",
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "# train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "train_labels_index = []\n",
        "for i in train_labels:\n",
        "    train_labels_index.append(word2idx[i])\n",
        "# print(train_labels_index)\n",
        "train_y = torch.tensor(train_labels_index)\n",
        "print(train_seq)\n",
        "print(train_mask)\n",
        "print(train_y)\n",
        "#train_y = torch.tensor(tokens_train_y['input_ids'])\n",
        "\n",
        "# for validation set\n",
        "val_labels_index = []\n",
        "for i in val_labels:\n",
        "    val_labels_index.append(word2idx[i])\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels_index)\n",
        "\n",
        "# for test set\n",
        "test_labels_index = []\n",
        "for i in test_labels:\n",
        "    test_labels_index.append(word2idx[i])\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101,  2191,  1037,  ...,     0,     0,     0],\n",
            "        [  101,  1999,  1996,  ...,     0,     0,     0],\n",
            "        [  101, 11158,  7182,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  3701,   102,  ...,     0,     0,     0],\n",
            "        [  101,  1037,  2601,  ...,     0,     0,     0],\n",
            "        [  101,  8800,  2000,  ...,     0,     0,     0]])\n",
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "tensor([ 172, 2696, 1941,  ..., 1997, 2324, 1140])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov1cOBlcRLuk"
      },
      "source": [
        "# Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUy9JKFYQYLp"
      },
      "source": [
        "# 14\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2HZc5ZYRV28"
      },
      "source": [
        "# Freeze BERT Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHZ0MC00RQA_"
      },
      "source": [
        "# 15\n",
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7ahGBUWRi3X"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3iEtGyYRd0A"
      },
      "source": [
        "# 16\n",
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,len(word2idx))\n",
        "      #self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "\n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBAJJVuJRliv"
      },
      "source": [
        "# 17\n",
        "# pass the pre-trained BERT to our defined architecture\n",
        "model = BERT_Arch(bert)\n",
        "# push the model to GPU\n",
        "#model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taXS0IilRn9J"
      },
      "source": [
        "# 18\n",
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CDpoMQR_rK"
      },
      "source": [
        "# Find Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izY5xH5eR7Ur",
        "outputId": "ac788014-0fc5-4267-b731-c24553db9f72"
      },
      "source": [
        "# 19\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', np.unique(train_labels_index), train_labels_index)\n",
        "\n",
        "print(class_wts)\n",
        "print(len(class_wts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.55432158 1.10864317 1.10864317 ... 1.10864317 1.10864317 1.10864317]\n",
            "2071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1WvfY2vSGKi"
      },
      "source": [
        "# 20\n",
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "#weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "#cross_entropy  = nn.NLLLoss(weight=weights)\n",
        "cross_entropy  = nn.NLLLoss(weight=None)  ###\n",
        "#criterion=nn.BCELoss()\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My4CA0qaShLq"
      },
      "source": [
        "# Fine-Tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskLk8R_SahS"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    # batch = [r.to(device) for r in batch]\n",
        "    \n",
        "    sent_id, mask, labels = batch\n",
        "    # sent_id.to(device)\n",
        "    # mask.to(device)\n",
        "    # labels.to(device)\n",
        "    # print(sent_id)\n",
        "    # print(\"MASK\")\n",
        "    # print(mask)\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "    # print(\"I am Here\")\n",
        "    # get model predictions for the current batch\n",
        "\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # print(\"I am Here too\")\n",
        "    # print(preds)\n",
        "    # print(len(preds))\n",
        "    # print(preds.shape)\n",
        "    # print(labels)\n",
        "    # print(len(labels))\n",
        "    # print(labels.shape)\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "    #loss=criterion(preds, labels)\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGXovFDlSxB5"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "  #  batch = [t.to(device) for t in batch]\n",
        "#    model.to(device)\n",
        "    sent_id, mask, labels = batch\n",
        "    # sent_id.to(device)\n",
        "    # mask.to(device)\n",
        "    # labels.to(device)\n",
        "    # outputs = model(**inputs)\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yrhUc9kTI5a"
      },
      "source": [
        "# Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OacxUyizS8d1",
        "outputId": "a7cce13a-16fb-4d34-834a-f23f953f18d4"
      },
      "source": [
        "# 21\n",
        "#load weights of best model\n",
        "path = '/content/drive/MyDrive/ReverseDictionary/models/saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZEgxRRTLXG"
      },
      "source": [
        "# Start Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1USGTntS3TS",
        "outputId": "0fed14a4-9a93-4d9c-afaf-254ef5c6d681"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(10):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/ReverseDictionary/models/saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of     72.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 7.199\n",
            "Validation Loss: 11.924\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of     72.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 7.155\n",
            "Validation Loss: 12.230\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of     72.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 7.090\n",
            "Validation Loss: 13.165\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of     72.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 7.028\n",
            "Validation Loss: 13.907\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of     72.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 6.979\n",
            "Validation Loss: 14.605\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of     72.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 6.948\n",
            "Validation Loss: 14.630\n",
            "\n",
            " Epoch 7 / 10\n",
            "  Batch    50  of     72.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 6.896\n",
            "Validation Loss: 15.271\n",
            "\n",
            " Epoch 8 / 10\n",
            "  Batch    50  of     72.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 6.866\n",
            "Validation Loss: 15.834\n",
            "\n",
            " Epoch 9 / 10\n",
            "  Batch    50  of     72.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 6.831\n",
            "Validation Loss: 16.133\n",
            "\n",
            " Epoch 10 / 10\n",
            "  Batch    50  of     72.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 6.820\n",
            "Validation Loss: 16.013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SVftkkTZXA"
      },
      "source": [
        "# Get Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZl0SZmFTRQA"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq, test_mask)\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms1ObHZxTYSI"
      },
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp0sO6lQW1XK"
      },
      "source": [
        "import numpy as np\n",
        "def evaluate(ground_truth, prediction):\n",
        "   accu_1 = 0.\n",
        "   accu_10 = 0.\n",
        "   accu_100 = 0.\n",
        "   length = len(ground_truth)\n",
        "   for i in range(length):\n",
        "       if ground_truth[i] in prediction[i][:100]:\n",
        "           accu_100 += 1\n",
        "           if ground_truth[i] in prediction[i][:10]:\n",
        "               accu_10 += 1\n",
        "               if ground_truth[i] == prediction[i][0]:\n",
        "                   accu_1 += 1\n",
        "   return accu_1/length*100, accu_10/length*100, accu_100/length*100\n",
        "\n",
        "def evaluate_test(ground_truth, prediction):\n",
        "   # print(ground_truth)\n",
        "   # print(prediction)\n",
        "   accu_1 = 0.\n",
        "   accu_10 = 0.\n",
        "   accu_100 = 0.\n",
        "   length = len(ground_truth)\n",
        "   l = 0\n",
        "   pred_rank = []\n",
        "   for i in range(length):\n",
        "      #  print(prediction[i].tolist().index(ground_truth[i]))\n",
        "       try:\n",
        "           pred_rank.append(prediction[i].tolist().index(ground_truth[i]))\n",
        "           l = l+1\n",
        "       except:\n",
        "           pred_rank.append(1000)\n",
        "\n",
        "       if ground_truth[i] in prediction[i][:100]:\n",
        "           accu_100 += 1\n",
        "           if ground_truth[i] in prediction[i][:10]:\n",
        "               accu_10 += 1\n",
        "               if ground_truth[i] == prediction[i][0]:\n",
        "                   accu_1 += 1\n",
        "   actual_pred_rank = []  \n",
        "   for i in range(length):\n",
        "     if(pred_rank[i]!=1000):\n",
        "        actual_pred_rank.append(pred_rank[i])\n",
        "   print(actual_pred_rank)\n",
        "   return accu_1/l*100, accu_10/l*100, accu_100/l*100, np.median(actual_pred_rank), np.sqrt(np.var(actual_pred_rank))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zFeLKKqW2IV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44a5feb5-2a34-494a-e46e-1f35c7123e79"
      },
      "source": [
        "predictions = []\n",
        "ground_truth = []\n",
        "test = open('/content/drive/MyDrive/ReverseDictionary/data/dataset2.csv', 'r')\n",
        "#test = open('dataset9.txt', 'r')\n",
        "for i, line in enumerate(test):\n",
        "    print(line)\n",
        "    if(i==200):\n",
        "      break\n",
        "    else:\n",
        "      print(\"Testing \" + str(i) + \"/200\")\n",
        "    line = line.strip('\\n').split(',')\n",
        "    # if(line[0] not in idx2word):\n",
        "    #   continue\n",
        "    ground_truth.append(word2idx[line[0]])\n",
        "    # print(ground_truth)\n",
        "    a = line[1]\n",
        "    text = []\n",
        "    text.append(a)\n",
        "    sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)\n",
        "    seq = torch.tensor(sent_id['input_ids'])\n",
        "    # print(seq)\n",
        "    mask = torch.tensor(sent_id['attention_mask'])\n",
        "    # mask\n",
        "    preds=model(seq,mask)\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "    #print(np.argmax(bert(seq)))\n",
        "    ind=np.argpartition(preds[0],-100)[-100:]\n",
        "    predictions.append(ind)\n",
        "    # print(predictions)\n",
        "\n",
        "A_1,A_10,A_100,med,sq = evaluate_test(ground_truth,predictions)\n",
        "print(\"Accuracy @ 1 = \"+ str(A_1))\n",
        "print(\"Accuracy @ 10 = \"+ str(A_10))\n",
        "print(\"Accuracy @ 100 = \"+ str(A_100))\n",
        "print(\"Median Prediction Rank = \"+ str(med))\n",
        "print(\"Variance = \"+ sq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label,text\n",
            "\n",
            "Testing 0/200\n",
            "abandon,Cease to support or look after (someone)\n",
            "\n",
            "Testing 1/200\n",
            "abandon,desert\n",
            "\n",
            "Testing 2/200\n",
            "ability,Possession of the means or skill to do something\n",
            "\n",
            "Testing 3/200\n",
            "able,Having the power skill means or opportunity to do something\n",
            "\n",
            "Testing 4/200\n",
            "abortion,The deliberate termination of a human pregnancy most often performed during the first 28 weeks of pregnancy\n",
            "\n",
            "Testing 5/200\n",
            "about,On the subject of\n",
            "\n",
            "Testing 6/200\n",
            "about,concerning\n",
            "\n",
            "Testing 7/200\n",
            "above,In extended space over and not touching\n",
            "\n",
            "Testing 8/200\n",
            "abroad,In or to a foreign country or countries\n",
            "\n",
            "Testing 9/200\n",
            "absence,The state of being away from a place or person\n",
            "\n",
            "Testing 10/200\n",
            "absolute,Not qualified or diminished in any way\n",
            "\n",
            "Testing 11/200\n",
            "absolute,total\n",
            "\n",
            "Testing 12/200\n",
            "absolutely,With no qualification restriction or limitation\n",
            "\n",
            "Testing 13/200\n",
            "absolutely,totally\n",
            "\n",
            "Testing 14/200\n",
            "absorb,Take in or soak up (energy or a liquid or other substance) by chemical or physical action\n",
            "\n",
            "Testing 15/200\n",
            "abuse,Use (something) to bad effect or for a bad purpose\n",
            "\n",
            "Testing 16/200\n",
            "abuse,misuse\n",
            "\n",
            "Testing 17/200\n",
            "academic,Relating to education and scholarship\n",
            "\n",
            "Testing 18/200\n",
            "accept,Consent to receive or undertake (something offered)\n",
            "\n",
            "Testing 19/200\n",
            "access,The means or opportunity to approach or enter a place\n",
            "\n",
            "Testing 20/200\n",
            "accident,An unfortunate incident that happens unexpectedly and unintentionally typically resulting in damage or injury\n",
            "\n",
            "Testing 21/200\n",
            "accompany,Go somewhere with (someone) as a companion or escort\n",
            "\n",
            "Testing 22/200\n",
            "accomplish,Achieve or complete successfully\n",
            "\n",
            "Testing 23/200\n",
            "according,As stated by or in\n",
            "\n",
            "Testing 24/200\n",
            "account,A report or description of an event or experience\n",
            "\n",
            "Testing 25/200\n",
            "accurate,(especially of information measurements or predictions) correct in all details\n",
            "\n",
            "Testing 26/200\n",
            "accurate,exact\n",
            "\n",
            "Testing 27/200\n",
            "accuse,Charge (someone) with an offence or crime\n",
            "\n",
            "Testing 28/200\n",
            "achieve,Successfully bring about or reach (a desired objective or result) by effort skill or courage\n",
            "\n",
            "Testing 29/200\n",
            "achievement,A thing done successfully with effort skill or courage\n",
            "\n",
            "Testing 30/200\n",
            "acid,A substance with particular chemical properties including turning litmus red neutralizing alkalis and dissolving some metals\n",
            "\n",
            "Testing 31/200\n",
            "acid,typically a corrosive or sour-tasting liquid of this kind\n",
            "\n",
            "Testing 32/200\n",
            "acknowledge,Accept or admit the existence or truth of\n",
            "\n",
            "Testing 33/200\n",
            "acquire,Buy or obtain (an asset or object) for oneself\n",
            "\n",
            "Testing 34/200\n",
            "across,From one side to the other of (a place area etc)\n",
            "\n",
            "Testing 35/200\n",
            "act,Take action\n",
            "\n",
            "Testing 36/200\n",
            "act,do something\n",
            "\n",
            "Testing 37/200\n",
            "action,The fact or process of doing something typically to achieve an aim\n",
            "\n",
            "Testing 38/200\n",
            "active,Engaging or ready to engage in physically energetic pursuits\n",
            "\n",
            "Testing 39/200\n",
            "activist,A person who campaigns to bring about political or social change\n",
            "\n",
            "Testing 40/200\n",
            "activity,The condition in which things are happening or being done\n",
            "\n",
            "Testing 41/200\n",
            "actor,A person whose profession is acting on the stage in films or on television\n",
            "\n",
            "Testing 42/200\n",
            "actress,A woman whose profession is acting on stage in films or on television\n",
            "\n",
            "Testing 43/200\n",
            "actual,Existing in fact\n",
            "\n",
            "Testing 44/200\n",
            "actual,real\n",
            "\n",
            "Testing 45/200\n",
            "actually,As the truth or facts of a situation\n",
            "\n",
            "Testing 46/200\n",
            "actually,really\n",
            "\n",
            "Testing 47/200\n",
            "ad,An advertisement\n",
            "\n",
            "Testing 48/200\n",
            "adapt,Make (something) suitable for a new use or purpose\n",
            "\n",
            "Testing 49/200\n",
            "adapt,modify\n",
            "\n",
            "Testing 50/200\n",
            "add,Join (something) to something else so as to increase the size number or amount\n",
            "\n",
            "Testing 51/200\n",
            "addition,The action or process of adding something to something else\n",
            "\n",
            "Testing 52/200\n",
            "additional,Added extra or supplementary to what is already present or available\n",
            "\n",
            "Testing 53/200\n",
            "address,The particulars of the place where someone lives or an organization is situated\n",
            "\n",
            "Testing 54/200\n",
            "adequate,Satisfactory or acceptable in quality or quantity\n",
            "\n",
            "Testing 55/200\n",
            "adjust,Alter or move (something) slightly in order to achieve the desired fit appearance or result\n",
            "\n",
            "Testing 56/200\n",
            "adjustment,A small alteration or movement made to achieve a desired fit appearance or result\n",
            "\n",
            "Testing 57/200\n",
            "administration,The process or activity of running a business organization etc\n",
            "\n",
            "Testing 58/200\n",
            "administrator,A person responsible for carrying out the administration of a business or organization\n",
            "\n",
            "Testing 59/200\n",
            "admire,Regard with respect or warm approval\n",
            "\n",
            "Testing 60/200\n",
            "admission,A statement acknowledging the truth of something\n",
            "\n",
            "Testing 61/200\n",
            "admit,Confess to be true or to be the case\n",
            "\n",
            "Testing 62/200\n",
            "adolescent,(of a young person) in the process of developing from a child into an adult\n",
            "\n",
            "Testing 63/200\n",
            "adopt,Legally take (another's child) and bring it up as one's own\n",
            "\n",
            "Testing 64/200\n",
            "adult,A person who is fully grown or developed\n",
            "\n",
            "Testing 65/200\n",
            "advance,Move forwards in a purposeful way\n",
            "\n",
            "Testing 66/200\n",
            "advanced,Far on or ahead in development or progress\n",
            "\n",
            "Testing 67/200\n",
            "advantage,A condition or circumstance that puts one in a favourable or superior position\n",
            "\n",
            "Testing 68/200\n",
            "adventure,An unusual and exciting or daring experience\n",
            "\n",
            "Testing 69/200\n",
            "advertising,The activity or profession of producing advertisements for commercial products or services\n",
            "\n",
            "Testing 70/200\n",
            "advice,Guidance or recommendations offered with regard to prudent future action\n",
            "\n",
            "Testing 71/200\n",
            "advise,Offer suggestions about the best course of action to someone\n",
            "\n",
            "Testing 72/200\n",
            "adviser,A person who gives advice in a particular field\n",
            "\n",
            "Testing 73/200\n",
            "advocate,A person who publicly supports or recommends a particular cause or policy\n",
            "\n",
            "Testing 74/200\n",
            "affair,An event or sequence of events of a specified kind or that has previously been referred to\n",
            "\n",
            "Testing 75/200\n",
            "affect,Have an effect on\n",
            "\n",
            "Testing 76/200\n",
            "affect,make a difference to\n",
            "\n",
            "Testing 77/200\n",
            "afford,Have enough money to pay for\n",
            "\n",
            "Testing 78/200\n",
            "afraid,Feeling fear or anxiety\n",
            "\n",
            "Testing 79/200\n",
            "afraid,frightened\n",
            "\n",
            "Testing 80/200\n",
            "after,In the time following (an event or another period of time)\n",
            "\n",
            "Testing 81/200\n",
            "afternoon,The time from noon or lunchtime to evening\n",
            "\n",
            "Testing 82/200\n",
            "again,Another time\n",
            "\n",
            "Testing 83/200\n",
            "again,once more\n",
            "\n",
            "Testing 84/200\n",
            "against,In opposition to\n",
            "\n",
            "Testing 85/200\n",
            "age,The length of time that a person has lived or a thing has existed\n",
            "\n",
            "Testing 86/200\n",
            "agency,A business or organization providing a particular service on behalf of another business person or group\n",
            "\n",
            "Testing 87/200\n",
            "agenda,A list of items to be discussed at a formal meeting\n",
            "\n",
            "Testing 88/200\n",
            "agent,A person who acts on behalf of another person or group\n",
            "\n",
            "Testing 89/200\n",
            "aggressive,Ready or likely to attack or confront\n",
            "\n",
            "Testing 90/200\n",
            "aggressive,characterized by or resulting from aggression\n",
            "\n",
            "Testing 91/200\n",
            "ago,Before the present\n",
            "\n",
            "Testing 92/200\n",
            "ago,earlier (used with a measurement of time\n",
            "\n",
            "Testing 93/200\n",
            "agree,Have the same opinion about something\n",
            "\n",
            "Testing 94/200\n",
            "agree,concur\n",
            "\n",
            "Testing 95/200\n",
            "agreement,Harmony or accordance in opinion or feeling\n",
            "\n",
            "Testing 96/200\n",
            "agricultural,Relating to agriculture\n",
            "\n",
            "Testing 97/200\n",
            "ah,Used to express a range of emotions including surprise pleasure sympathy and realization\n",
            "\n",
            "Testing 98/200\n",
            "ahead,Further forward in space\n",
            "\n",
            "Testing 99/200\n",
            "ahead,in the line of one's forward motion\n",
            "\n",
            "Testing 100/200\n",
            "aid,Help typically of a practical nature\n",
            "\n",
            "Testing 101/200\n",
            "aide,An assistant to an important person especially a political leader\n",
            "\n",
            "Testing 102/200\n",
            "aim,Point or direct (a weapon or camera) at a target\n",
            "\n",
            "Testing 103/200\n",
            "air,The invisible gaseous substance surrounding the earth a mixture mainly of oxygen and nitrogen\n",
            "\n",
            "Testing 104/200\n",
            "aircraft,An aeroplane helicopter or other machine capable of flight\n",
            "\n",
            "Testing 105/200\n",
            "airline,An organization providing a regular public service of air transport on one or more routes\n",
            "\n",
            "Testing 106/200\n",
            "airport,A complex of runways and buildings for the take-off landing and maintenance of civil aircraft with facilities for passengers\n",
            "\n",
            "Testing 107/200\n",
            "album,A blank book for the insertion of photographs stamps or pictures\n",
            "\n",
            "Testing 108/200\n",
            "alcohol,A colourless volatile flammable liquid which is produced by the natural fermentation of sugars and is the intoxicating constituent of wine beer spirits and other drinks and is also used as an industrial solvent and as fuel\n",
            "\n",
            "Testing 109/200\n",
            "alive,(of a person animal or plant) living not dead\n",
            "\n",
            "Testing 110/200\n",
            "all,Used to refer to the whole quantity or extent of a particular group or thing\n",
            "\n",
            "Testing 111/200\n",
            "alliance,A union or association formed for mutual benefit especially between countries or organizations\n",
            "\n",
            "Testing 112/200\n",
            "allow,Let (someone) have or do something\n",
            "\n",
            "Testing 113/200\n",
            "ally,A state formally cooperating with another for a military or other purpose\n",
            "\n",
            "Testing 114/200\n",
            "almost,Not quite\n",
            "\n",
            "Testing 115/200\n",
            "almost,very nearly\n",
            "\n",
            "Testing 116/200\n",
            "alone,Having no one else present\n",
            "\n",
            "Testing 117/200\n",
            "alone,on one's own\n",
            "\n",
            "Testing 118/200\n",
            "along,Moving in a constant direction on (a more or less horizontal surface)\n",
            "\n",
            "Testing 119/200\n",
            "already,Before or by now or the time in question\n",
            "\n",
            "Testing 120/200\n",
            "also,In addition\n",
            "\n",
            "Testing 121/200\n",
            "also,too\n",
            "\n",
            "Testing 122/200\n",
            "alter,Change in character or composition typically in a comparatively small but significant way\n",
            "\n",
            "Testing 123/200\n",
            "alternative,(of one or more things) available as another possibility or choice\n",
            "\n",
            "Testing 124/200\n",
            "although,In spite of the fact that\n",
            "\n",
            "Testing 125/200\n",
            "although,even though\n",
            "\n",
            "Testing 126/200\n",
            "always,At all times\n",
            "\n",
            "Testing 127/200\n",
            "always,on all occasions\n",
            "\n",
            "Testing 128/200\n",
            "amazing,Causing great surprise or wonder\n",
            "\n",
            "Testing 129/200\n",
            "amazing,astonishing\n",
            "\n",
            "Testing 130/200\n",
            "among,Situated more or less centrally in relation to (several other things)\n",
            "\n",
            "Testing 131/200\n",
            "amount,A quantity of something especially the total of a thing or things in number size value or extent\n",
            "\n",
            "Testing 132/200\n",
            "analysis,Detailed examination of the elements or structure of something\n",
            "\n",
            "Testing 133/200\n",
            "analyst,A person who conducts analysis\n",
            "\n",
            "Testing 134/200\n",
            "analyze,Examine (something) methodically and in detail typically in order to explain and interpret it\n",
            "\n",
            "Testing 135/200\n",
            "ancient,Belonging to the very distant past and no longer in existence\n",
            "\n",
            "Testing 136/200\n",
            "and,Used to connect words of the same part of speech clauses or sentences that are to be taken jointly\n",
            "\n",
            "Testing 137/200\n",
            "anger,A strong feeling of annoyance displeasure or hostility\n",
            "\n",
            "Testing 138/200\n",
            "angle,The space (usually measured in degrees) between two intersecting lines or surfaces at or close to the point where they meet\n",
            "\n",
            "Testing 139/200\n",
            "angry,Feeling or showing strong annoyance displeasure or hostility\n",
            "\n",
            "Testing 140/200\n",
            "angry,full of anger\n",
            "\n",
            "Testing 141/200\n",
            "animal,A living organism that feeds on organic matter typically having specialized sense organs and nervous system and able to respond rapidly to stimuli\n",
            "\n",
            "Testing 142/200\n",
            "anniversary,The date on which an event took place or an institution was founded in a previous year\n",
            "\n",
            "Testing 143/200\n",
            "announce,Make a formal public statement about a fact occurrence or intention\n",
            "\n",
            "Testing 144/200\n",
            "annual,Occurring once every year\n",
            "\n",
            "Testing 145/200\n",
            "another,Used to refer to an additional person or thing of the same type as one already mentioned or known about\n",
            "\n",
            "Testing 146/200\n",
            "another,one mor\n",
            "\n",
            "Testing 147/200\n",
            "another,a further\n",
            "\n",
            "Testing 148/200\n",
            "answer,A thing that is said written or done as a reaction to a question statement or situation\n",
            "\n",
            "Testing 149/200\n",
            "anticipate,Regard as probable\n",
            "\n",
            "Testing 150/200\n",
            "anticipate,expect or predict\n",
            "\n",
            "Testing 151/200\n",
            "anxiety,A feeling of worry nervousness or unease about something with an uncertain outcome\n",
            "\n",
            "Testing 152/200\n",
            "any,Used to refer to one or some of a thing or number of things no matter how much or how many\n",
            "\n",
            "Testing 153/200\n",
            "anybody,Anyone\n",
            "\n",
            "Testing 154/200\n",
            "anymore,To any further extent\n",
            "\n",
            "Testing 155/200\n",
            "anymore,any longer\n",
            "\n",
            "Testing 156/200\n",
            "anyone,Any person or people\n",
            "\n",
            "Testing 157/200\n",
            "anything,Used to refer to a thing no matter what\n",
            "\n",
            "Testing 158/200\n",
            "anyway,Used to confirm or support a point or idea just mentioned\n",
            "\n",
            "Testing 159/200\n",
            "anywhere,In or to any place\n",
            "\n",
            "Testing 160/200\n",
            "apart,(of two or more people or things) separated by a specified distance in time or space\n",
            "\n",
            "Testing 161/200\n",
            "apartment,A flat typically one that is well appointed or used for holidays\n",
            "\n",
            "Testing 162/200\n",
            "apparent,Clearly visible or understood\n",
            "\n",
            "Testing 163/200\n",
            "apparent,obvious\n",
            "\n",
            "Testing 164/200\n",
            "apparently,As far as one knows or can see\n",
            "\n",
            "Testing 165/200\n",
            "appeal,Make a serious urgent or heartfelt request\n",
            "\n",
            "Testing 166/200\n",
            "appear,Come into sight\n",
            "\n",
            "Testing 167/200\n",
            "appear,become visible or noticeable especially without apparent cause\n",
            "\n",
            "Testing 168/200\n",
            "appearance,The way that someone or something looks\n",
            "\n",
            "Testing 169/200\n",
            "apple,The round fruit of a tree of the rose family which typically has thin green or red skin and crisp flesh\n",
            "\n",
            "Testing 170/200\n",
            "application,A formal request to be considered for a position or to be allowed to do or have something submitted to an authority institution or organization\n",
            "\n",
            "Testing 171/200\n",
            "apply,Make a formal application or request\n",
            "\n",
            "Testing 172/200\n",
            "appoint,Assign a job or role to (someone)\n",
            "\n",
            "Testing 173/200\n",
            "appointment,An arrangement to meet someone at a particular time and place\n",
            "\n",
            "Testing 174/200\n",
            "appreciate,Recognize the full worth of\n",
            "\n",
            "Testing 175/200\n",
            "approach,Come near or nearer to (someone or something) in distance or time\n",
            "\n",
            "Testing 176/200\n",
            "appropriate,Suitable or proper in the circumstances\n",
            "\n",
            "Testing 177/200\n",
            "approval,The action of approving something\n",
            "\n",
            "Testing 178/200\n",
            "approve,Officially agree to or accept as satisfactory\n",
            "\n",
            "Testing 179/200\n",
            "approximately,Used to show that something is almost but not completely accurate or exact\n",
            "\n",
            "Testing 180/200\n",
            "approximately,roughly\n",
            "\n",
            "Testing 181/200\n",
            "architect,A person who designs buildings and in many cases also supervises their construction\n",
            "\n",
            "Testing 182/200\n",
            "area,A region or part of a town a country or the world\n",
            "\n",
            "Testing 183/200\n",
            "argue,Give reasons or cite evidence in support of an idea action or theory typically with the aim of persuading others to share one's view\n",
            "\n",
            "Testing 184/200\n",
            "argument,An exchange of diverging or opposite views typically a heated or angry one\n",
            "\n",
            "Testing 185/200\n",
            "arise,(of a problem opportunity or situation) emerge\n",
            "\n",
            "Testing 186/200\n",
            "arise,become apparent\n",
            "\n",
            "Testing 187/200\n",
            "arm,Each of the two upper limbs of the human body from the shoulder to the hand\n",
            "\n",
            "Testing 188/200\n",
            "armed,Equipped with or carrying a firearm or firearms\n",
            "\n",
            "Testing 189/200\n",
            "army,An organized military force equipped for fighting on land\n",
            "\n",
            "Testing 190/200\n",
            "around,Located or situated on every side\n",
            "\n",
            "Testing 191/200\n",
            "arrange,Put (things) in a neat attractive or required order\n",
            "\n",
            "Testing 192/200\n",
            "arrangement,The action process or result of arranging or being arranged\n",
            "\n",
            "Testing 193/200\n",
            "arrest,Seize (someone) by legal authority and take them into custody\n",
            "\n",
            "Testing 194/200\n",
            "arrival,The action or process of arriving\n",
            "\n",
            "Testing 195/200\n",
            "arrive,Reach a place at the end of a journey or a stage in a journey\n",
            "\n",
            "Testing 196/200\n",
            "art,The expression or application of human creative skill and imagination typically in a visual form such as painting or sculpture producing works to be appreciated primarily for their beauty or emotional power\n",
            "\n",
            "Testing 197/200\n",
            "article,A particular item or object\n",
            "\n",
            "Testing 198/200\n",
            "artist,A person who creates paintings or drawings as a profession or hobby\n",
            "\n",
            "Testing 199/200\n",
            "artistic,Having or revealing natural creative skill\n",
            "\n",
            "[4, 96, 96, 17, 28, 3, 16, 42, 5, 41, 17, 49, 58, 56, 3, 29, 13, 12, 17, 53, 34, 63, 40, 29, 41]\n",
            "Accuracy @ 1 = 0.0\n",
            "Accuracy @ 10 = 16.0\n",
            "Accuracy @ 100 = 100.0\n",
            "Median Prediction Rank = 29.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-9d5b2f5cfc9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy @ 100 = \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Median Prediction Rank = \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Variance = \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0msq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: must be str, not numpy.float64"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC3PcP5cMNQv",
        "outputId": "0e44413f-071c-46b7-eff7-eaf161e43640"
      },
      "source": [
        "a = input()\n",
        "text = []\n",
        "text.append(a)\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)\n",
        "\n",
        "seq = torch.tensor(sent_id['input_ids'])\n",
        "# print(seq)\n",
        "mask = torch.tensor(sent_id['attention_mask'])\n",
        "# mask\n",
        "preds=model(seq,mask)\n",
        "preds = preds.detach().cpu().numpy()\n",
        "#answer=int((np.argmax(preds, axis = None)+np.argmin(preds, axis = None))/2)\n",
        "print(preds)\n",
        "answer=np.argmin(preds, axis=1)\n",
        "print(answer[0])\n",
        "idx2word[answer[0]]\n",
        "# print(model.predict_class(seq))\n",
        "#print(np.argmax(bert(seq)))\n",
        "ind=np.argpartition(preds[0],-10)[-10:]\n",
        "meanings=[]\n",
        "for i in ind:\n",
        "    meanings.append(idx2word[i])\n",
        "print(meanings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "happines\n",
            "[[ -6.407955  -8.473671 -15.365709 ... -15.346077 -15.245441 -12.765114]]\n",
            "1273\n",
            "['honor', 'nobody', 'ultimately', 'five', 'first', 'hundred', 'somewhat', 'thirty', 'nevertheless', 'ten']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4lLZtKSOf1o",
        "outputId": "8297397b-1563-4078-d158-fd49967d67de"
      },
      "source": [
        "# 22\n",
        "!pip install flask-ngrok\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, jsonify, render_template, logging \n",
        "import webbrowser "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIqwemfZn29d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpX1uTwjUPY6",
        "outputId": "1bda3133-b868-448d-f65d-08036d3d4811"
      },
      "source": [
        "# 23\n",
        "def create_app():\n",
        "    app = Flask(__name__, template_folder='/content/drive/MyDrive/Colab Notebooks/templates', static_folder='/content/drive/MyDrive/Colab Notebooks/static')  \n",
        "    return app\n",
        "    \n",
        "app = create_app()\n",
        "\n",
        "#WEB-APP\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def index():\n",
        "    meanings=[]\n",
        "    if request.method == 'POST':\n",
        "        words = request.form['definition'].split()        \n",
        "        sent_id = tokenizer.batch_encode_plus(words, padding=True, return_token_type_ids=False)\n",
        "        seq = torch.tensor(sent_id['input_ids'])\n",
        "        mask = torch.tensor(sent_id['attention_mask'])\n",
        "        preds=model(seq,mask)\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        ind=np.argpartition(preds[0],-10)[-10:]\n",
        "        meanings=[]\n",
        "        for i in ind:\n",
        "            meanings.append(idx2word[i])\n",
        "        return jsonify(meanings)        \n",
        "    else:\n",
        "        #return \"<h1>Running Flask on Google Colab!</h1>\"\n",
        "        return render_template('indexBERT.html')\n",
        "\n",
        "\n",
        "run_with_ngrok(app) \n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://e8c85b68f812.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [07/Dec/2020 04:30:41] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:30:43] \"\u001b[37mGET /static/js/main.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:30:43] \"\u001b[37mGET /static/js/jquery-3.3.1.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:30:43] \"\u001b[37mGET /static/css/bulma/bulma.min.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:30:47] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:44:49] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:45:05] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:45:23] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:45:45] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:45:50] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:45:52] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:45:54] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:46:05] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:46:23] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:46:37] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:46:51] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 04:47:13] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 06:01:51] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 06:01:51] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}